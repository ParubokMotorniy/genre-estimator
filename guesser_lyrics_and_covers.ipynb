{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1_JSQ2q3IzLi",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d9876c7-5aa8-4a83-cec3-640d2f01cae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.10/dist-packages (2.29.0)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.20.1+cu121)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (2024.9.11)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (6.3.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (4.66.6)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.26.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (0.4.5)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch) (1.0.11)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9.0->open_clip_torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9.0->open_clip_torch) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch) (0.2.13)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->open_clip_torch) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->open_clip_torch) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9.0->open_clip_torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->open_clip_torch) (2024.8.30)\n",
            "Requirement already satisfied: clip-retrieval in /usr/local/lib/python3.10/dist-packages (2.44.0)\n",
            "Requirement already satisfied: img2dataset<2,>=1.25.5 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (1.45.0)\n",
            "Requirement already satisfied: clip-anytorch<3,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (2.6.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (4.66.6)\n",
            "Requirement already satisfied: fire<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (0.5.0)\n",
            "Requirement already satisfied: torch<3,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy<2,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (1.26.4)\n",
            "Requirement already satisfied: faiss-cpu<2,>=1.7.2 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (1.9.0.post1)\n",
            "Requirement already satisfied: flask<4,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (3.0.3)\n",
            "Requirement already satisfied: flask-restful<1,>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (0.3.10)\n",
            "Requirement already satisfied: flask-cors<5,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (4.0.2)\n",
            "Requirement already satisfied: pandas<3,>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<15,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (14.0.2)\n",
            "Requirement already satisfied: autofaiss<3,>=2.9.6 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (2.17.0)\n",
            "Requirement already satisfied: webdataset<0.3,>=0.2 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (0.2.100)\n",
            "Requirement already satisfied: h5py<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (3.12.1)\n",
            "Requirement already satisfied: prometheus-client<1,>=0.13.1 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (0.21.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (2024.10.0)\n",
            "Requirement already satisfied: sentence-transformers<3,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (2.7.0)\n",
            "Requirement already satisfied: wandb<0.17,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (0.16.6)\n",
            "Requirement already satisfied: open-clip-torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (2.29.0)\n",
            "Requirement already satisfied: requests<3,>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (2.32.3)\n",
            "Requirement already satisfied: aiohttp<4,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (3.11.2)\n",
            "Requirement already satisfied: multilingual-clip<2,>=1.0.10 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (1.0.10)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (4.46.2)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (1.26.20)\n",
            "Requirement already satisfied: scipy<1.12 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (1.11.4)\n",
            "Requirement already satisfied: all-clip<2 in /usr/local/lib/python3.10/dist-packages (from clip-retrieval) (1.2.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.8.1->clip-retrieval) (4.0.3)\n",
            "Requirement already satisfied: embedding-reader<2,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from autofaiss<3,>=2.9.6->clip-retrieval) (1.7.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip-anytorch<3,>=2.5.0->clip-retrieval) (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip-anytorch<3,>=2.5.0->clip-retrieval) (2024.9.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu<2,>=1.7.2->clip-retrieval) (24.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire<0.6.0,>=0.4.0->clip-retrieval) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire<0.6.0,>=0.4.0->clip-retrieval) (2.5.0)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask<4,>=3.0.0->clip-retrieval) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask<4,>=3.0.0->clip-retrieval) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask<4,>=3.0.0->clip-retrieval) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask<4,>=3.0.0->clip-retrieval) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask<4,>=3.0.0->clip-retrieval) (1.9.0)\n",
            "Requirement already satisfied: aniso8601>=0.82 in /usr/local/lib/python3.10/dist-packages (from flask-restful<1,>=0.3.9->clip-retrieval) (9.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from flask-restful<1,>=0.3.9->clip-retrieval) (2024.2)\n",
            "Requirement already satisfied: opencv-python-headless<5,>=4.5.5.62 in /usr/local/lib/python3.10/dist-packages (from img2dataset<2,>=1.25.5->clip-retrieval) (4.10.0.84)\n",
            "Requirement already satisfied: exifread-nocycle<4,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from img2dataset<2,>=1.25.5->clip-retrieval) (3.0.1)\n",
            "Requirement already satisfied: albumentations<2,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from img2dataset<2,>=1.25.5->clip-retrieval) (1.4.20)\n",
            "Requirement already satisfied: dataclasses<1.0.0,>=0.6 in /usr/local/lib/python3.10/dist-packages (from img2dataset<2,>=1.25.5->clip-retrieval) (0.6)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from open-clip-torch<3.0.0,>=2.0.0->clip-retrieval) (0.26.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from open-clip-torch<3.0.0,>=2.0.0->clip-retrieval) (0.4.5)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open-clip-torch<3.0.0,>=2.0.0->clip-retrieval) (1.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.1.5->clip-retrieval) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.1.5->clip-retrieval) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.1->clip-retrieval) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.1->clip-retrieval) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.1->clip-retrieval) (2024.8.30)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3,>=2.2.0->clip-retrieval) (1.5.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers<3,>=2.2.0->clip-retrieval) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7.1->clip-retrieval) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7.1->clip-retrieval) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7.1->clip-retrieval) (3.4.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3,>=1.7.1->clip-retrieval) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3,>=1.7.1->clip-retrieval) (1.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->clip-retrieval) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->clip-retrieval) (0.20.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.12.0->clip-retrieval) (3.1.43)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.12.0->clip-retrieval) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.12.0->clip-retrieval) (2.18.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.12.0->clip-retrieval) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.12.0->clip-retrieval) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.12.0->clip-retrieval) (75.1.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.12.0->clip-retrieval) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.12.0->clip-retrieval) (4.25.5)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset<0.3,>=0.2->clip-retrieval) (0.1.7)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations<2,>=1.1.0->img2dataset<2,>=1.25.5->clip-retrieval) (2.9.2)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations<2,>=1.1.0->img2dataset<2,>=1.25.5->clip-retrieval) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations<2,>=1.1.0->img2dataset<2,>=1.25.5->clip-retrieval) (0.2.0)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations<2,>=1.1.0->img2dataset<2,>=1.25.5->clip-retrieval) (3.10.10)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb<0.17,>=0.12.0->clip-retrieval) (4.0.11)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask<4,>=3.0.0->clip-retrieval) (3.0.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip-anytorch<3,>=2.5.0->clip-retrieval) (0.2.13)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3,>=2.2.0->clip-retrieval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers<3,>=2.2.0->clip-retrieval) (3.5.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb<0.17,>=0.12.0->clip-retrieval) (5.0.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations<2,>=1.1.0->img2dataset<2,>=1.25.5->clip-retrieval) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations<2,>=1.1.0->img2dataset<2,>=1.25.5->clip-retrieval) (2.23.4)\n",
            "Requirement already satisfied: img2dataset in /usr/local/lib/python3.10/dist-packages (1.45.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (4.66.6)\n",
            "Requirement already satisfied: opencv-python-headless<5,>=4.5.5.62 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (4.10.0.84)\n",
            "Requirement already satisfied: fire<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (0.5.0)\n",
            "Requirement already satisfied: webdataset<0.3,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (0.2.100)\n",
            "Requirement already satisfied: pandas<3,>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<16,>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (14.0.2)\n",
            "Requirement already satisfied: exifread-nocycle<4,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (3.0.1)\n",
            "Requirement already satisfied: albumentations<2,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (1.4.20)\n",
            "Requirement already satisfied: dataclasses<1.0.0,>=0.6 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (0.6)\n",
            "Requirement already satisfied: wandb<0.17,>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from img2dataset) (0.16.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from img2dataset) (2024.10.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (1.11.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (2.9.2)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations<2,>=1.1.0->img2dataset) (0.2.0)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations<2,>=1.1.0->img2dataset) (3.10.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire<0.6.0,>=0.4.0->img2dataset) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire<0.6.0,>=0.4.0->img2dataset) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.1.5->img2dataset) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.1.5->img2dataset) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.1.5->img2dataset) (2024.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (2.32.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (2.18.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (75.1.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb<0.17,>=0.16.0->img2dataset) (4.25.5)\n",
            "Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset<0.3,>=0.2.5->img2dataset) (0.1.7)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb<0.17,>=0.16.0->img2dataset) (4.0.11)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations<2,>=1.1.0->img2dataset) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations<2,>=1.1.0->img2dataset) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations<2,>=1.1.0->img2dataset) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb<0.17,>=0.16.0->img2dataset) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb<0.17,>=0.16.0->img2dataset) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb<0.17,>=0.16.0->img2dataset) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb<0.17,>=0.16.0->img2dataset) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb<0.17,>=0.16.0->img2dataset) (5.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autofaiss 2.17.0 requires pyarrow<16,>=6.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
            "clip-retrieval 2.44.0 requires pyarrow<15,>=6.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
            "cudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\n",
            "embedding-reader 1.7.0 requires pyarrow<16,>=6.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "img2dataset 1.45.0 requires pyarrow<16,>=6.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
            "pylibcudf-cu12 24.10.1 requires pyarrow<18.0.0a0,>=14.0.0, but you have pyarrow 18.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.1.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 pyarrow-18.1.0 xxhash-3.5.0\n",
            "Collecting umap-learn\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.5.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
            "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.13 umap-learn-0.5.7\n",
            "Collecting datashader\n",
            "  Downloading datashader-0.16.3-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from datashader) (3.1.0)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (from datashader) (2024.10.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader) (1.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from datashader) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from datashader) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datashader) (2.2.2)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader) (2.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from datashader) (11.0.0)\n",
            "Collecting pyct (from datashader)\n",
            "  Downloading pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from datashader) (1.11.4)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from datashader) (0.12.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datashader) (24.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader) (2024.10.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (2024.9.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (6.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (8.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->datashader) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datashader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datashader) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datashader) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->datashader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->datashader) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->datashader) (2024.8.30)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask->datashader) (3.21.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask->datashader) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datashader) (1.16.0)\n",
            "Downloading datashader-0.16.3-py2.py3-none-any.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyct, datashader\n",
            "Successfully installed datashader-0.16.3 pyct-0.5.0\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh) (1.26.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh) (24.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\n",
            "Requirement already satisfied: holoviews in /usr/local/lib/python3.10/dist-packages (1.20.0)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from holoviews) (3.6.1)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from holoviews) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from holoviews) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from holoviews) (24.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from holoviews) (2.2.2)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from holoviews) (1.5.4)\n",
            "Requirement already satisfied: param<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from holoviews) (2.1.1)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.10/dist-packages (from holoviews) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (1.3.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (2024.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->holoviews) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->holoviews) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->holoviews) (2024.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (0.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh>=3.1->holoviews) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3->holoviews) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->holoviews) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->holoviews) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->holoviews) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->holoviews) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->holoviews) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->holoviews) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->holoviews) (2024.8.30)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.3.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Collecting transformers==4.45.2\n",
            "  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers==3.1.1\n",
            "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.1.1) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.1.1) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.1.1) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.1.1) (11.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.1.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.1.1) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.1.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers==3.1.1) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==3.1.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==3.1.1) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.1.1) (3.0.2)\n",
            "Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers, sentence-transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.2\n",
            "    Uninstalling transformers-4.46.2:\n",
            "      Successfully uninstalled transformers-4.46.2\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 2.7.0\n",
            "    Uninstalling sentence-transformers-2.7.0:\n",
            "      Successfully uninstalled sentence-transformers-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "clip-retrieval 2.44.0 requires pyarrow<15,>=6.0.1, but you have pyarrow 18.1.0 which is incompatible.\n",
            "clip-retrieval 2.44.0 requires sentence-transformers<3,>=2.2.0, but you have sentence-transformers 3.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sentence-transformers-3.1.1 transformers-4.45.2\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-0i8rquht\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-0i8rquht\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.20.1+cu121)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=bd992129b5f35262461f2428c91896b5cbb59c3eb3eebe626ce354c82a531575\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s4p0olyu/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.18.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install open_clip_torch\n",
        "%pip install clip-retrieval\n",
        "%pip install img2dataset\n",
        "%pip install  torch\n",
        "%pip install  transformers\n",
        "%pip install  accelerate\n",
        "%pip install  datasets\n",
        "%pip install  umap-learn\n",
        "%pip install  datashader\n",
        "%pip install  bokeh\n",
        "%pip install  holoviews\n",
        "%pip install ftfy regex tqdm\n",
        "%pip install transformers==4.45.2 sentence-transformers==3.1.1\n",
        "%pip install git+https://github.com/openai/CLIP.git\n",
        "%pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJcDjK55q4uX",
        "outputId": "7b9a9229-5e8b-4c3b-b4fc-d63b1347a345"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG-NBViNt71W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset,Dataset, concatenate_datasets\n",
        "import numpy as np\n",
        "from time import process_time\n",
        "import math\n",
        "import random\n",
        "import joblib\n",
        "import umap\n",
        "import umap.plot\n",
        "import tqdm\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from sentence_transformers import SentenceTransformer,SentenceTransformerTrainingArguments\n",
        "from sentence_transformers.losses import BatchAllTripletLoss, BatchHardSoftMarginTripletLoss, BatchHardTripletLoss\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import BatchSamplers\n",
        "from sentence_transformers.evaluation import TripletEvaluator\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *DATASET PROCESSING*"
      ],
      "metadata": {
        "id": "QFuRgyJPzlVy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AQ5d2RUz_K5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e68e4fe9624240eab1ec164d33083dfe",
            "b10a2dccb87d4727af317eb95ebc3074",
            "789dd1a095a147768a4dab65ebc89da9",
            "43e176395c704439846e0d25c819f361",
            "3107475876824820bce4cf8dfa619510",
            "abbb6a8f8ca745c8bb8fb49d7ea67fd8",
            "be643cc63bc44107b2571f5998e67583",
            "5db2f60f6d584f71857fdf47e26f5b92",
            "60503fce0afb4947a57b0ed94f5fe985",
            "d1aae315cdaa4636a95517fb891ffc30",
            "c53ac40abb174b0da2a3a9528add5e62"
          ]
        },
        "outputId": "83b93122-c084-48fc-924f-85b3f1e1cbf0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e68e4fe9624240eab1ec164d33083dfe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset(\"csv\", data_files=\"./tcc_ceds_music.csv\")\n",
        "dataset = dataset.remove_columns([\"artist_name\", \"track_name\"])\n",
        "dataset = dataset.rename_columns({\"genre\":\"label\", \"lyrics\":\"sentence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9x3rM4Ia9kjn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b83ffd7f55474ff5a1e221e86d97d364",
            "e421048330e04f7a8ced3c8a0fa73c88",
            "b456d48bc37e42ce92caa189acc0fb76",
            "0d948bbeb0574a9892b785fe1e9b0956",
            "151d353d3f4a49a4ace0c815c049b4ef",
            "a607b2dcb5804e8595a8a79682057706",
            "aca3e69f8bef4f1f9db084838ec1dba4",
            "5d9df7964443490286ed35ee8ea2f6c1",
            "354659732624407a81ea82b629987833",
            "ce3c35259ab34e78adac011215310ca8",
            "76a9dbbc6a704bcca48ae2cc54cac493"
          ]
        },
        "outputId": "05459525-f8cf-4de6-ec72-aaa4fc408e21"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/28372 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b83ffd7f55474ff5a1e221e86d97d364"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "unique_genres = dataset['train'].unique('label')\n",
        "genre_to_index = {label: idx for idx, label in enumerate(unique_genres)}\n",
        "\n",
        "def label_to_index_func(data_set):\n",
        "    data_set['label'] = genre_to_index[data_set['label']]\n",
        "    return data_set\n",
        "\n",
        "dataset = dataset.map(label_to_index_func)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "genre_idx_delimiters = []\n",
        "prev_genre = -1\n",
        "\n",
        "for i in range(len(dataset['train'])):\n",
        "  genre_idx = int(dataset['train'][i]['label'])\n",
        "  if genre_idx != prev_genre:\n",
        "    genre_idx_delimiters.append(i)\n",
        "    prev_genre = genre_idx"
      ],
      "metadata": {
        "id": "yUj38AOYvYxu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *COVER EMBEDDING PART*"
      ],
      "metadata": {
        "id": "OUchV2NwkbA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "//TODO:post-train a clip model on my tiny dataset"
      ],
      "metadata": {
        "id": "l4ZihnX-m9OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cover_dataset_source_path = \"/content/drive/MyDrive/AIDatasets/retrieved_covers.zip\"\n",
        "cover_extraction_directory = \"./retrieved_covers\"\n",
        "cover_embeddings_root_path = \"./cover_embeddings\""
      ],
      "metadata": {
        "id": "JWpXqts1w2uX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip {cover_dataset_source_path} -d ./"
      ],
      "metadata": {
        "id": "FTSw6Ph4r1hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OFkxtfv74Kt",
        "outputId": "7088d97c-c237-4538-9196-a598520eca6f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import clip\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "RgwNDuph1Fvl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!clip-retrieval inference --input_dataset {cover_extraction_directory} --output_folder {cover_embeddings_root_path} --enable_wandb True --clip_model \"open_clip:ViT-B-32/laion2b_s34b_b79k\""
      ],
      "metadata": {
        "id": "rSCnK3Rl4yoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#covers for some songs have not been retrieved, so from now on we are effectively workign with a subset of the input dataset\n",
        "available_song_indices = []\n",
        "genres = []\n",
        "\n",
        "for filename in sorted(os.listdir(cover_extraction_directory)):\n",
        "\n",
        "    entry_idx = int(filename.split('_')[0])\n",
        "    available_song_indices.append(entry_idx)\n",
        "    genres.append(dataset['train'][entry_idx]['label'])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Eoe8XOXZkoMl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covers_embeddings = np.load(f\"{cover_embeddings_root_path}/img_emb/img_emb_0.npy\")"
      ],
      "metadata": {
        "id": "RjyA8mvHDZNP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cover_embedding_size = len(covers_embeddings[0])\n",
        "covers_embeddings_df = pd.DataFrame(covers_embeddings)\n",
        "covers_embeddings_df['genres'] = genres"
      ],
      "metadata": {
        "id": "dn2iVrlCKqq5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(covers_embeddings_df, \"embeddings_of_all_covers.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31K9i3KfQ-1f",
        "outputId": "f7ce3b78-3a2c-4153-ec5e-3a92bf394cb3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['embeddings_of_all_covers_0.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "covers_embeddings_df = joblib.load(\"embeddings_of_all_covers.pkl\")"
      ],
      "metadata": {
        "id": "zHz6eItLF5zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk_besBpgPvp"
      },
      "source": [
        "### *LYRICS EMBEDDER PART*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-T4t6Hp3qTps"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer(\"sentence-transformers/all-distilroberta-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQbwzIR4gPvq"
      },
      "outputs": [],
      "source": [
        "# populate with permuted lyrics\n",
        "n_songs_to_permute = len(dataset['train'])\n",
        "n_permutations = 4\n",
        "\n",
        "permuted_lyrics = []\n",
        "lables_of_permuted = []\n",
        "\n",
        "for i in range(n_songs_to_permute):\n",
        "    song_item = dataset['train'][i]\n",
        "    label = song_item['label']\n",
        "    sentence = song_item['sentence'].split(' ')\n",
        "\n",
        "    for ii in range(n_permutations):\n",
        "        permuted_song = \" \".join(random.sample(sentence, len(sentence)))\n",
        "        permuted_lyrics.append(permuted_song)\n",
        "        lables_of_permuted.append(label)\n",
        "\n",
        "permuted_dataset = Dataset.from_dict({\"sentence\":permuted_lyrics, \"label\":lables_of_permuted})\n",
        "dataset['train'] = concatenate_datasets([dataset['train'], permuted_dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKfvMC-ugPvq"
      },
      "outputs": [],
      "source": [
        "train_test_split = dataset['train'].train_test_split(test_size=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAFDHUIwKaMO"
      },
      "outputs": [],
      "source": [
        "loss = BatchHardTripletLoss(model,margin=7)\n",
        "training_args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=\"./models/guesser_2\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-6,\n",
        "    warmup_ratio=0.15,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.01,\n",
        "    use_cpu=False,\n",
        "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
        "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
        "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
        "    # Optional tracking/debugging parameters:\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=50,\n",
        "    seed=135)\n",
        "\n",
        "    # eval_strategy=\"steps\",\n",
        "    # eval_steps=100,\n",
        "    # save_strategy=\"steps\","
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PB5MqoaEUro"
      },
      "outputs": [],
      "source": [
        "train_set = train_test_split['train']\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_set,\n",
        "    loss=loss,\n",
        "    args=training_args\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q010H_zeW5VY"
      },
      "outputs": [],
      "source": [
        "#save the embedding model\n",
        "model.save_pretrained(\"trained-embedder-permute\")\n",
        "! tar -czf trained_embedder.tar.gz ./trained-embedder-permute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kEpO0tbW5VX"
      },
      "outputs": [],
      "source": [
        "#creates test dataset to evaluate the embedder\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "class_groups = defaultdict(list)\n",
        "for example in train_test_split['test']:\n",
        "    class_groups[example['label']].append(example['sentence'])\n",
        "\n",
        "triplets = []\n",
        "\n",
        "for label, sentences in class_groups.items():\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(i + 1, len(sentences)):\n",
        "            anchor = sentences[i]\n",
        "            positive = sentences[j]\n",
        "\n",
        "            negative_label = random.choice([lbl for lbl in class_groups.keys() if lbl != label])\n",
        "            negative = random.choice(class_groups[negative_label])\n",
        "\n",
        "            triplets.append({\n",
        "                'anchor': anchor,\n",
        "                'positive': positive,\n",
        "                'negative': negative\n",
        "            })\n",
        "\n",
        "triplet_test_dataset = Dataset.from_list(triplets)\n",
        "triplet_test_dataset = triplet_test_dataset.shuffle(seed=83)\n",
        "\n",
        "print(triplet_test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkS5NdAXW5VY"
      },
      "outputs": [],
      "source": [
        "test_evaluator = TripletEvaluator(\n",
        "    anchors=triplet_test_dataset[\"anchor\"],\n",
        "    positives=triplet_test_dataset[\"positive\"],\n",
        "    negatives=triplet_test_dataset[\"negative\"],\n",
        "    name=\"all-test\",\n",
        ")\n",
        "print(test_evaluator(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7AvVv3AvlW6"
      },
      "outputs": [],
      "source": [
        "#load the saved embedding model\n",
        "! tar -xzf ./trained_embedder_permute.tar.gz ./\n",
        "model = SentenceTransformer(\"trained-embedder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Qma2ILplQAsr"
      },
      "outputs": [],
      "source": [
        "def get_lyrics_embedding(lyrics:str):\n",
        "  return model.encode([lyrics.lower()])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = model.get_sentence_embedding_dimension()"
      ],
      "metadata": {
        "id": "nnZ5qxd6K867"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_NpIF9PgPvs"
      },
      "source": [
        "### *ESTIMATOR PART*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVG7byPW26_k"
      },
      "outputs": [],
      "source": [
        "#creates a dataframe of all songs as embeddings -> genre as idx\n",
        "\n",
        "lyrics_embeddigs = []\n",
        "genres = []\n",
        "unique_genres_set = set()\n",
        "\n",
        "import string\n",
        "songs_and_lyrics = pd.read_csv('./tcc_ceds_music.csv')\n",
        "\n",
        "for idx in range(len(songs_and_lyrics)):\n",
        "  genre = songs_and_lyrics[\"genre\"][idx]\n",
        "  unique_genres_set.add(genre)\n",
        "\n",
        "  lyrics_as_bag_of_words_string = str(songs_and_lyrics[\"lyrics\"][idx])\n",
        "\n",
        "  embedding =  get_lyrics_embedding(lyrics_as_bag_of_words_string)[0]\n",
        "  lyrics_embeddigs.append(embedding)\n",
        "  genres.append(genre)\n",
        "\n",
        "embedding_set = pd.DataFrame({\"genres\":genres})\n",
        "embeddings_list = []\n",
        "\n",
        "for i in range(embedding_size):\n",
        "  dim_i = pd.Series([embedding[i] for embedding in lyrics_embeddigs])\n",
        "  embeddings_list.append(dim_i)\n",
        "\n",
        "embeddings_df = pd.concat(embeddings_list, axis=1)\n",
        "embedding_set = pd.concat([embeddings_df, embedding_set], axis=1)\n",
        "\n",
        "embedding_set['genres'] = embedding_set['genres'].apply(lambda genre: genre_to_index[genre])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFRKJwszev8_"
      },
      "outputs": [],
      "source": [
        "#save embeddings of all songs\n",
        "joblib.dump(embedding_set, \"embedding_set_of_all_songs_permute.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PJi4jq9DhbpG"
      },
      "outputs": [],
      "source": [
        "#load the embeddigns of al songs\n",
        "embedding_set = joblib.load(\"embedding_set_of_all_songs_permute_epoch5.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dimensionality reduction for lyrics embeddings\n",
        "\n",
        "ifReduceDimensionality = False\n",
        "reductionFactor = 2\n",
        "metric = 'euclidean'\n",
        "\n",
        "ifPlotReduced = False\n",
        "\n",
        "if ifPlotReduced:\n",
        "  actual_embedding_set = embedding_set.iloc[:, :-1]\n",
        "\n",
        "  dim_reducer = umap.UMAP( n_neighbors=5,\n",
        "        min_dist=0.2,\n",
        "        n_components=2,\n",
        "        metric=metric\n",
        "  )\n",
        "  pure_reductions = dim_reducer.fit(actual_embedding_set)\n",
        "  umap.plot.points(pure_reductions, labels=np.array([unique_genres[i] for i in embedding_set['genres']]), theme='green', show_legend=True)\n",
        "\n",
        "if ifReduceDimensionality:\n",
        "  actual_embedding_set = embedding_set.iloc[:, :-1]\n",
        "\n",
        "  embedding_size_reduced = int(embedding_size / reductionFactor)\n",
        "\n",
        "  dim_reducer = umap.UMAP( n_neighbors=10,\n",
        "        min_dist=0.15,\n",
        "        n_components=embedding_size_reduced,\n",
        "        metric=metric\n",
        "  )\n",
        "  reduced_embeddings = pd.DataFrame(dim_reducer.fit_transform(actual_embedding_set), columns = [i for i in range(embedding_size_reduced)])\n",
        "  print(reduced_embeddings.shape)\n",
        "  reduced_embeddings['genres'] = embedding_set['genres']\n",
        "\n",
        "  embedding_size = embedding_size_reduced\n",
        "  embedding_set = reduced_embeddings\n",
        "  print(reduced_embeddings.head(15))\n",
        "\n"
      ],
      "metadata": {
        "id": "hSEg2eWubnMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "pEIE7rbAybpD"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "#transforms the training embedding data into torch-compliant format. selects only data items for whom both cover and lyrics are available.\n",
        "\n",
        "features_lyrics = embedding_set.iloc[available_song_indices, :-1].values\n",
        "features_covers = covers_embeddings_df.iloc[:, :-1].values\n",
        "\n",
        "features_combined = np.concatenate((features_lyrics, features_covers), axis=1)\n",
        "\n",
        "labels = embedding_set.iloc[available_song_indices, -1].values\n",
        "sparse_labels = []\n",
        "for genre_label in labels:\n",
        "  sparse_arr = [0 for i in range(len(unique_genres))]\n",
        "  sparse_arr[genre_label] = 1\n",
        "  sparse_labels.append(sparse_arr)\n",
        "\n",
        "features_tensor = torch.tensor(features_combined, dtype=torch.float32)\n",
        "labels_tensor = torch.tensor(sparse_labels, dtype=torch.float32)\n",
        "\n",
        "dataset_train = torch.utils.data.TensorDataset(features_tensor, labels_tensor)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#transforms the testing embedding data into torch-compliant format\n",
        "\n",
        "test_size = 10000\n",
        "rand_indices_local = np.random.randint(0, len(available_song_indices), size=test_size)\n",
        "rand_indices_absolute = [available_song_indices[i] for i in rand_indices_local] #indirect indexing\n",
        "\n",
        "features_lyrics = embedding_set.iloc[rand_indices_absolute, :-1].values\n",
        "features_covers = covers_embeddings_df.iloc[rand_indices_local, :-1].values\n",
        "labels = embedding_set.iloc[rand_indices_absolute, -1].values\n",
        "\n",
        "features_combined = np.concatenate((features_lyrics, features_covers), axis=1)\n",
        "\n",
        "features_tensor = torch.tensor(features_combined, dtype=torch.float32)\n",
        "labels_tensor = torch.tensor(labels, dtype=torch.int32)\n",
        "\n",
        "dataset_test = torch.utils.data.TensorDataset(features_tensor, labels_tensor)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "7YHVTHoO1TAs"
      },
      "outputs": [],
      "source": [
        "#the nn used for genre estimation\n",
        "#now receives 768 from lyrics and 512 from cover packed into x\n",
        "\n",
        "# class NeuralGuesser40Conv(nn.Module):\n",
        "#     def __init__(self, embedding_size:int):\n",
        "#         super().__init__()\n",
        "#         self.num_conv_output_channels = 3\n",
        "\n",
        "#         self.pre_conv1 = nn.Conv1d(1,self.num_conv_output_channels,7,stride=1,padding=\"same\")\n",
        "#         self.prelu_weights = nn.Parameter(torch.ones(self.num_conv_output_channels))\n",
        "\n",
        "#         # self.layer0 = nn.Linear(int(embedding_size), int(embedding_size/2))\n",
        "\n",
        "#         self.layer0 = nn.Linear(int(embedding_size * self.num_conv_output_channels), int(embedding_size/2))\n",
        "#         self.layer1 = nn.Linear(int(embedding_size/2), int(embedding_size/3))\n",
        "#         # self.layerExp = nn.Linear(int(embedding_size/3), embedding_size)\n",
        "#         self.layer2 = nn.Linear(int(embedding_size/3), int(embedding_size/6))\n",
        "#         self.layer3 = nn.Linear(int(embedding_size/6), int(embedding_size/12))\n",
        "\n",
        "#         self.layer4 = nn.Linear(int(embedding_size/12), len(unique_genres))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.prelu(self.pre_conv1(x), self.prelu_weights)\n",
        "#         x = torch.flatten(x,1)\n",
        "\n",
        "#         x = F.relu(self.layer0(x))\n",
        "#         x = F.relu(self.layer1(x))\n",
        "#         # x = F.relu(self.layerExp(x))\n",
        "#         x = F.relu(self.layer2(x))\n",
        "#         x = F.relu(self.layer3(x))\n",
        "#         x = self.layer4(x)\n",
        "\n",
        "#         return x\n",
        "\n",
        "class NeuralGuesser(nn.Module):\n",
        "    def __init__(self, lyrics_embedding_size:int, covers_embedding_size:int, first_common_dimension:int):\n",
        "        super(NeuralGuesser, self).__init__()\n",
        "\n",
        "        self.les = lyrics_embedding_size\n",
        "        self.ces = covers_embedding_size\n",
        "\n",
        "        #lyrics layers\n",
        "        self.lyrics_layer_0 = nn.Linear(int(lyrics_embedding_size), int(lyrics_embedding_size/2)) #maybe init with prelu\n",
        "        self.lyrics_layer_1 = nn.Linear(int(lyrics_embedding_size/2), int(lyrics_embedding_size/3))\n",
        "        self.lyrics_layer_2 = nn.Linear(int(lyrics_embedding_size/3), int(lyrics_embedding_size/6))\n",
        "        self.lyrics_layer_3 = nn.Linear(int(lyrics_embedding_size/6), first_common_dimension)\n",
        "\n",
        "        #cover layers\n",
        "        num_out_conv_channels = 32\n",
        "        kernel_size = 8\n",
        "        self.cover_layers_0 = nn.Conv1d(1,num_out_conv_channels, kernel_size, stride=kernel_size) #gives length of covers_embedding_size/kernel_size (64)\n",
        "        self.prelu_weights = nn.Parameter(torch.ones(num_out_conv_channels))\n",
        "\n",
        "        self.cover_layers_1 = nn.AvgPool1d(num_out_conv_channels, num_out_conv_channels) #flatten before this\n",
        "        self.cover_layers_2 = nn.Linear(int(covers_embedding_size/kernel_size), first_common_dimension)\n",
        "\n",
        "        #common layers\n",
        "        num_final_conv_channels = 64\n",
        "        self.common_layer_0 = nn.Conv1d(2, 1, 3, padding=\"same\", padding_mode=\"zeros\")\n",
        "        self.common_layer_1 = nn.Conv1d(1,num_final_conv_channels, 4, padding=\"same\", padding_mode=\"zeros\") #maybe pool average\n",
        "\n",
        "        self.common_layer_2 = nn.Linear(num_final_conv_channels * first_common_dimension, first_common_dimension)#flatten before this\n",
        "        self.common_layer_3 = nn.Linear(first_common_dimension,int(first_common_dimension/3))\n",
        "        self.common_layer_4 = nn.Linear(int(first_common_dimension/3), len(unique_genres))\n",
        "\n",
        "    def forward(self, x):\n",
        "        lyrics_part = x[:, :self.les]\n",
        "\n",
        "        cover_part = x[:, self.les:]\n",
        "        cover_part = cover_part[:,None,:] #adding a dimension to be able to feed it through convolution\n",
        "\n",
        "        # print(\"Lyrics initial part shape:\", lyrics_part.shape)\n",
        "        # print(\"Cover initial part shape:\", cover_part.shape)\n",
        "\n",
        "        #lyrics forward\n",
        "        lyrics_part = F.silu(self.lyrics_layer_0(lyrics_part))\n",
        "        lyrics_part = F.relu(self.lyrics_layer_1(lyrics_part))\n",
        "        lyrics_part = F.relu(self.lyrics_layer_2(lyrics_part))\n",
        "        lyrics_part = F.relu(self.lyrics_layer_3(lyrics_part))\n",
        "\n",
        "        #cover forward\n",
        "        cover_part = F.prelu(self.cover_layers_0(cover_part), self.prelu_weights)\n",
        "        # cover_part = F.relu(self.cover_layers_0(cover_part))\n",
        "        cover_part = torch.flatten(cover_part,1) #flattening\n",
        "        cover_part = self.cover_layers_1(cover_part) #averaging\n",
        "        cover_part = F.relu(self.cover_layers_2(cover_part))\n",
        "\n",
        "        #combining parts\n",
        "        # print(\"Lyrics merge part shape:\", lyrics_part.shape)\n",
        "        # print(\"Cover merge part shape:\", cover_part.shape)\n",
        "\n",
        "        x = torch.stack([lyrics_part, cover_part], dim=0) #maps channel -> batch -> embedding\n",
        "        x = torch.permute(x, (1,0,2)) #now maps batch -> channel -> embedding\n",
        "\n",
        "        # print(\"Two-channel merged tensor shape:\", x.shape)\n",
        "\n",
        "        x = F.leaky_relu(self.common_layer_0(x))\n",
        "        x = F.relu(self.common_layer_1(x))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.common_layer_2(x))\n",
        "        x = F.relu(self.common_layer_3(x))\n",
        "        x = F.relu(self.common_layer_4(x))\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 964
        },
        "id": "CsIqJdF0AUCa",
        "outputId": "f9c74d2f-bac7-4550-e698-d7aa89c5a042"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (4x512 and 64x128)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-8f5a9a4698af>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguesser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_alg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-87-466780a61cf2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mcover_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_part\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#flattening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcover_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcover_layers_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_part\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#averaging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mcover_part\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcover_layers_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_part\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m#combining parts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (4x512 and 64x128)"
          ]
        }
      ],
      "source": [
        "#training the nn\n",
        "class_weights = torch.tensor(np.array([0.1282, 0.1357,0.1398, 0.1436, 0.1505, 0.1426, 0.1592]), dtype=torch.float32) #as computed from the entire dataset\n",
        "\n",
        "guesser = NeuralGuesser(embedding_size, cover_embedding_size, 128)\n",
        "loss_alg = nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.Adam(guesser.parameters(), lr=0.0005, betas=(0.9, 0.99))\n",
        "\n",
        "for epoch in range(7):\n",
        "\n",
        "    current_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_data_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        # print(\"Inputs shape:\", inputs.shape)\n",
        "        # print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = guesser(inputs)\n",
        "        loss = loss_alg(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        current_loss += loss.item()\n",
        "        if i % 500 == 499:\n",
        "            print(f'Mean loss for [{epoch + 1}, {i + 1:5d}] : {current_loss / 500:.3f}')\n",
        "            current_loss = 0.0\n",
        "\n",
        "torch.save(guesser.state_dict(), \"./trained-nn.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "satthA5pdnmB",
        "outputId": "0b2258b7-918e-4f04-84d5-af308555d7ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for 10000 test songs: 19 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in test_data_loader:\n",
        "        inputs, labels = data\n",
        "        outputs = guesser(inputs)\n",
        "\n",
        "        value, predicted_classes = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_classes == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy for 10000 test songs: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *INPUT LYRICS PROCESSING PART*"
      ],
      "metadata": {
        "id": "g0uQuWCpa-PO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EHMrwu4PdXq",
        "outputId": "efc89be0-8a6a-4e68-b05e-ab18cfa203c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "%pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer as wnl\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGXn5FAiC7vR"
      },
      "outputs": [],
      "source": [
        "part_of_speech_mapper = {\n",
        "    'NN': 'n', 'NNS': 'n', 'NNP': 'n', 'NNPS': 'n',\n",
        "    'VB': 'v', 'VBD': 'v', 'VBG': 'v', 'VBN': 'v', 'VBP': 'v', 'VBZ': 'v',\n",
        "    'JJ': 'a', 'JJR': 'a', 'JJS': 'a',\n",
        "    'RB': 'r', 'RBR': 'r', 'RBS': 'r',\n",
        "    'PDT': 'a',\n",
        "    'WRB': 'r',\n",
        "    '$': None, \"''\": None, '(': None, ')': None, ',': None, '--': None, '.': None,\n",
        "    ':': None, 'CC': None, 'CD': None, 'DT': None, 'EX': None, 'FW': None, 'IN': None,\n",
        "    'LS': None, 'MD': None, 'POS': None, 'PRP': None, 'PRP$': None, 'RP': None,\n",
        "    'SYM': None, 'TO': None, 'UH': None, 'WDT': None, 'WP': None, 'WP$': None,\n",
        "    '``': None,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgVk6T3Uah64"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "symbols = set([\",\",\".\",\"/\",\"#\",\"*\",\"(\",\")\",\"?\",\"+\",\"=\",\":\",\";\",\"%\",\"[\", \"]\"])\n",
        "song_specific = set([\"chorus\", \"repeat\", \"verse\", \"oh\", \"ooh\", \"ah\", \"aah\"])\n",
        "\n",
        "def check_if_not_to_be_removed(token:str):\n",
        "  return (not token.lower() in stop_words) and (not token.lower() in symbols) and (not token.lower() in song_specific) and (not any(char.isdigit() for char in token)) and (not \"'\" in token)\n",
        "\n",
        "def transform_lyrics(lyrics:str):\n",
        "  tokenized_lyrics = word_tokenize(lyrics)\n",
        "\n",
        "  tagged_lyrics = nltk.pos_tag(tokenized_lyrics)\n",
        "  lemmatized_lyrics = [wnl().lemmatize(word.lower(), pos=part_of_speech_mapper[assumed_pos]) for word,assumed_pos in tagged_lyrics if part_of_speech_mapper[assumed_pos] != None]\n",
        "  filtered_lyrics = [w.lower() for w in lemmatized_lyrics if check_if_not_to_be_removed(w)]\n",
        "\n",
        "  deduplicated_lyrics = \"\"\n",
        "  last_word = \"\"\n",
        "  for word in filtered_lyrics:\n",
        "    if word != last_word:\n",
        "      deduplicated_lyrics += f\"{word} \"\n",
        "      last_word = word\n",
        "\n",
        "  print(\"Tokenized lyrics:\", ' '.join(tokenized_lyrics))\n",
        "  print(\"Lemmatized lyrics:\", ' '.join(lemmatized_lyrics))\n",
        "  print(\"Transformed lyrics:\", deduplicated_lyrics)\n",
        "\n",
        "  return deduplicated_lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8RyFbtXa7ya"
      },
      "outputs": [],
      "source": [
        "def estimate_genre(model, song_lyrics):\n",
        "  filtered_lyrics = transform_lyrics(song_lyrics)\n",
        "\n",
        "  embedding = get_lyrics_embedding(filtered_lyrics)\n",
        "  model_prompt = torch.tensor(embedding, dtype=torch.float32)[:,None,:] #only if using convolutional layer\n",
        "\n",
        "  #get estimate here\n",
        "  prediction = model(model_prompt)\n",
        "\n",
        "  value, genre = torch.max(prediction, 1)\n",
        "\n",
        "  #map to the actual genre\n",
        "  for key,item in genre_to_index.items():\n",
        "    if genre == item:\n",
        "      return key\n",
        "\n",
        "  return -1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *EXPERIMENTS PART*"
      ],
      "metadata": {
        "id": "x_RC3YHUbGYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN4g-Xe0bilE",
        "outputId": "ef5f18c7-0996-425e-84fd-05fd9a3a10c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized lyrics: Ooh You can dance You can jive Having the time of your life Ooh , see that girl Watch that scene Digging the dancing queen Friday night and the lights are low Looking out for a place to go Where they play the right music Getting in the swing You come to look for a king Anybody could be that guy Night is young and the music 's high With a bit of rock music Everything is fine You 're in the mood for a dance And when you get the chance You are the dancing queen Young and sweet Only seventeen Dancing queen Feel the beat from the tambourine , oh yeah You can dance You can jive Having the time of your life Ooh , see that girl Watch that scene Digging the dancing queen You 're a teaser , you turn 'em on Leave 'em burning and then you 're gone Looking out for another Anyone will do You 're in the mood for a dance And when you get the chance You are the dancing queen Young and sweet Only seventeen Dancing queen Feel the beat from the tambourine , oh yeah You can dance You can jive Having the time of your life Ooh , see that girl Watch that scene Digging the dancing queen Digging the dancing queen\n",
            "Lemmatized lyrics: dance jive have time life ooh see girl watch scene dig dance queen friday night light be low look place go where play right music get swing come look king anybody be guy night be young music high bit rock music everything be fine 're mood dance when get chance be dance queen young sweet only seventeen dance queen feel beat tambourine dance jive have time life ooh see girl watch scene dig dance queen 're teaser turn leave 'em burning then 're go look anyone do 're mood dance when get chance be dance queen young sweet only seventeen dance queen feel beat tambourine dance jive have time life ooh see girl watch scene dig dance queen dig dancing queen\n",
            "Transformed lyrics: dance jive time life see girl watch scene dig dance queen friday night light low look place go play right music get swing come look king anybody guy night young music high bit rock music everything fine mood dance get chance dance queen young sweet seventeen dance queen feel beat tambourine dance jive time life see girl watch scene dig dance queen teaser turn leave burning go look anyone mood dance get chance dance queen young sweet seventeen dance queen feel beat tambourine dance jive time life see girl watch scene dig dance queen dig dancing queen \n",
            "pop\n"
          ]
        }
      ],
      "source": [
        "lyrics=\"Ooh You can dance You can jive Having the time of your life Ooh, see that girl Watch that scene Digging the dancing queen Friday night and the lights are low Looking out for a place to go Where they play the right music Getting in the swing You come to look for a king Anybody could be that guy Night is young and the music's high With a bit of rock music Everything is fine You're in the mood for a dance And when you get the chance You are the dancing queen Young and sweet Only seventeen Dancing queen Feel the beat from the tambourine, oh yeah You can dance You can jive Having the time of your life Ooh, see that girl Watch that scene Digging the dancing queen You're a teaser, you turn 'em on Leave 'em burning and then you're gone Looking out for another Anyone will do You're in the mood for a dance And when you get the chance You are the dancing queen Young and sweet Only seventeen Dancing queen Feel the beat from the tambourine, oh yeah You can dance You can jive Having the time of your life Ooh, see that girl Watch that scene Digging the dancing queen Digging the dancing queen\"\n",
        "print(estimate_genre(guesser, lyrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNs-Uo6He_rE",
        "outputId": "5cb487c1-7ecb-4be4-9dd3-39b492b80545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized lyrics: Half past twelve And I 'm watchin ' the late show in my flat , all alone How I hate to spend the evening on my own Autumn winds Blowin ' outside the window as I look around the room And it makes me so depressed to see the gloom There 's not a soul out there No one to hear my prayer Gim me , gim me , gim me a man after midnight Wo n't somebody help me chase these shadows away ? Gim me , gim me , gim me a man after midnight Take me through the darkness to the break of the day Movie stars Find the end of the rainbow with a fortune to win It 's so different from the world I 'm living in Tired of TV I open the window and I gaze into the night But there 's nothing there to see , no one in sight There 's not a soul out there No one to hear my prayer Gim me , gim me , gim me a man after midnight Wo n't somebody help me chase these shadows away ? Gim me , gim me , gim me a man after midnight Take me through the darkness to the break of the day Gim me , gim me , gim me a man after midnight Gim me , gim me , gim me a man after midnight There 's not a soul out there No one to hear my prayer Gim me , gim me , gim me a man after midnight Wo n't somebody help me chase these shadows away ? Gim me , gim me , gim me a man after midnight Take me through the darkness to the break of the day Gim me , gim me , gim me a man after midnight Wo n't somebody help me chase these shadows away ? Gim me , gim me , gim me a man after midnight Take me through the darkness to the break of the day\n",
            "Lemmatized lyrics: half past twelve 'm watchin late show flat alone how hate spend evening own autumn wind blowin window look room make so depress see gloom 's not soul there one hear prayer gim gim gim man midnight wo n't somebody help chase shadow gim gim gim man midnight take darkness break day movie star end rainbow fortune win 's so different world 'm live tired tv open window gaze night 's nothing there see one sight 's not soul there one hear prayer gim gim gim man midnight wo n't somebody help chase shadow gim gim gim man midnight take darkness break day gim gim gim man midnight gim gim gim man midnight 's not soul there one hear prayer gim gim gim man midnight wo n't somebody help chase shadow gim gim gim man midnight take darkness break day gim gim gim man midnight wo n't somebody help chase shadow gim gim gim man midnight take darkness break day\n",
            "Transformed lyrics: half past twelve watchin late show flat alone hate spend evening autumn wind blowin window look room make depress see gloom soul one hear prayer gim man midnight wo somebody help chase shadow gim man midnight take darkness break day movie star end rainbow fortune win different world live tired tv open window gaze night nothing see one sight soul one hear prayer gim man midnight wo somebody help chase shadow gim man midnight take darkness break day gim man midnight gim man midnight soul one hear prayer gim man midnight wo somebody help chase shadow gim man midnight take darkness break day gim man midnight wo somebody help chase shadow gim man midnight take darkness break day \n",
            "pop\n"
          ]
        }
      ],
      "source": [
        "lyrics=\"Half past twelve And I'm watchin' the late show in my flat, all alone How I hate to spend the evening on my own Autumn winds Blowin' outside the window as I look around the room And it makes me so depressed to see the gloom There's not a soul out there No one to hear my prayer Gimme, gimme, gimme a man after midnight Won't somebody help me chase these shadows away? Gimme, gimme, gimme a man after midnight Take me through the darkness to the break of the day Movie stars Find the end of the rainbow with a fortune to win It's so different from the world I'm living in Tired of TV I open the window and I gaze into the night But there's nothing there to see, no one in sight There's not a soul out there No one to hear my prayer Gimme, gimme, gimme a man after midnight Won't somebody help me chase these shadows away? Gimme, gimme, gimme a man after midnight Take me through the darkness to the break of the day Gimme, gimme, gimme a man after midnight Gimme, gimme, gimme a man after midnight There's not a soul out there No one to hear my prayer Gimme, gimme, gimme a man after midnight Won't somebody help me chase these shadows away? Gimme, gimme, gimme a man after midnight Take me through the darkness to the break of the day Gimme, gimme, gimme a man after midnight Won't somebody help me chase these shadows away? Gimme, gimme, gimme a man after midnight Take me through the darkness to the break of the day\"\n",
        "print(estimate_genre(guesser, lyrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wydBqDgP8Ibu",
        "outputId": "bc89d1ec-137b-4137-f16e-9451425a22d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized lyrics: You 'll take my life but I 'll take yours , too You 'll fire your musket but I 'll run you through So when you 're waiting for the next attack You 'd better stand , there 's no turning back The bugle sounds , the charge begins But on this battlefield , no one wins The smell of acrid smoke and horses ' breath As I plunge on into certain death Oh Oh The horse he sweats with fear , we break to run The mighty roar of the Russian guns And as we race towards the human wall The screams of pain as my comrades fall We hurdle bodies that lay on the ground And the Russians fire another round We get so near yet so far away We wo n't live to fight another day Oh Oh We get so close , near enough to fight When a Russian gets me in his sights He pulls the trigger and I feel the blow A burst of rounds take my horse below And as I lay there gazing at the sky My body 's numb and my throat is dry And as I lay forgotten and alone Without a tear I draw my parting groan Oh Oh\n",
            "Lemmatized lyrics: take life take yours too fire musket run so when 're wait next attack good stand 's turn bugle sound charge begin battlefield one win smell acrid smoke horse breath plunge certain death oh oh horse sweat fear break run mighty roar russian gun race human wall scream pain comrade fall hurdle body lay ground russian fire round get so near yet so far away n't live fight day oh oh get so close enough fight when russian get sight pull trigger feel blow burst round take horse below lay there gaze sky my body numb throat be dry lay forgotten alone tear draw parting groan oh oh\n",
            "Transformed lyrics: take life take fire musket run wait next attack good stand turn bugle sound charge begin battlefield one win smell acrid smoke horse breath plunge certain death horse sweat fear break run mighty roar russian gun race human wall scream pain comrade fall hurdle body lay ground russian fire round get near yet far away live fight day get close enough fight russian get sight pull trigger feel blow burst round take horse lay gaze sky body numb throat dry lay forgotten alone tear draw parting groan \n",
            "pop\n"
          ]
        }
      ],
      "source": [
        "lyrics=\"You'll take my life but I'll take yours, too You'll fire your musket but I'll run you through So when you're waiting for the next attack You'd better stand, there's no turning back The bugle sounds, the charge begins But on this battlefield, no one wins The smell of acrid smoke and horses' breath As I plunge on into certain death Oh Oh The horse he sweats with fear, we break to run The mighty roar of the Russian guns And as we race towards the human wall The screams of pain as my comrades fall We hurdle bodies that lay on the ground And the Russians fire another round We get so near yet so far away We won't live to fight another day Oh Oh We get so close, near enough to fight When a Russian gets me in his sights He pulls the trigger and I feel the blow A burst of rounds take my horse below And as I lay there gazing at the sky My body's numb and my throat is dry And as I lay forgotten and alone Without a tear I draw my parting groan Oh Oh\"\n",
        "print(estimate_genre(guesser, lyrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBGhWbBvgPvt",
        "outputId": "5bcbb12d-3e1b-4a22-d419-3bf7a4c7ccb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized lyrics: How I 've waited for you to come I 've been here all alone Now that you 've arrived Please stay awhile And I promise I wo n't keep you long I 'll keep you forever ( forever , forever , forever ) Graze the skin with my fingertips The brush of dead , cold flesh appease the means Provoking images , delicate features so smooth A pleasant fragrance in the light of the moon Dance with the dead in my dreams Listen to their hallowed screams The dead have taken my soul Temptation 's lost all control Simple smiles elude psychotic eyes Lose all mind control , rationale declines Empty eyes enslave the creations Of placid faces and lifeless pageants In the depths of a mind insane Fantasy and reality are the same Graze the skin with my fingertips The brush of dead , warm flesh pacifies the means Incised members ornaments on my being Adulating the skin before me Simple smiles elude psychotic eyes Lose all mind control , rationale declines Empty eyes enslave the creations Of placid faces and lifeless pageants Dance with the dead in my dreams ( Hello ? Hello , Mr . Gein ? ) Listen to their hallowed screams ( Mr . Gein ? ) The dead have taken my soul ( let me out of here , Mr. Gein ) Temptation 's lost all control ( Mr. Gein ? I do n't want to play anymore , Mr. Gein ) Dance with the dead in my dreams ( Mr. Gein , this is n't fun anymore ) Listen to their hallowed screams ( I do n't wan na play anymore , Mr. Gein , Mr . Gein ? ) The dead have taken my soul ( I want out of here , Mr. Gein ) Temptation 's lost all control ( let me out now )\n",
            "Lemmatized lyrics: how 've wait come 've be here alone now 've arrive please stay promise n't keep long keep forever forever forever forever graze skin fingertip brush dead cold flesh appease mean provoking image delicate feature so smooth a pleasant fragrance light moon dance dead dream listen hallow scream dead have take soul temptation lost control simple smile elude psychotic eye lose mind control rationale decline empty eye enslave creation placid face lifeless pageant depth mind insane fantasy reality be same graze skin fingertip brush dead warm flesh pacify mean incise member ornament be adulate skin simple smile elude psychotic eye lose mind control rationale decline empty eye enslave creation placid face lifeless pageant dance dead dream hello hello mr gein listen hallow scream mr gein dead have take soul let here mr. gein temptation lost control mr. gein do n't want play anymore mr. gein dance dead dream mr. gein be n't fun anymore listen hallow scream do n't wan na play anymore mr. gein mr gein dead have take soul want here mr. gein temptation lost control let now\n",
            "Transformed lyrics: wait come alone arrive please stay promise keep long keep forever graze skin fingertip brush dead cold flesh appease mean provoking image delicate feature smooth pleasant fragrance light moon dance dead dream listen hallow scream dead take soul temptation lost control simple smile elude psychotic eye lose mind control rationale decline empty eye enslave creation placid face lifeless pageant depth mind insane fantasy reality graze skin fingertip brush dead warm flesh pacify mean incise member ornament adulate skin simple smile elude psychotic eye lose mind control rationale decline empty eye enslave creation placid face lifeless pageant dance dead dream hello mr gein listen hallow scream mr gein dead take soul let mr. gein temptation lost control mr. gein want play anymore mr. gein dance dead dream mr. gein fun anymore listen hallow scream wan na play anymore mr. gein mr gein dead take soul want mr. gein temptation lost control let \n",
            "pop\n"
          ]
        }
      ],
      "source": [
        "lyrics=\"How I've waited for you to come I've been here all alone Now that you've arrived Please stay awhile And I promise I won't keep you long I'll keep you forever (forever, forever, forever) Graze the skin with my fingertips The brush of dead, cold flesh appease the means Provoking images, delicate features so smooth A pleasant fragrance in the light of the moon Dance with the dead in my dreams Listen to their hallowed screams The dead have taken my soul Temptation's lost all control Simple smiles elude psychotic eyes Lose all mind control, rationale declines Empty eyes enslave the creations Of placid faces and lifeless pageants In the depths of a mind insane Fantasy and reality are the same Graze the skin with my fingertips The brush of dead, warm flesh pacifies the means Incised members ornaments on my being Adulating the skin before me Simple smiles elude psychotic eyes Lose all mind control, rationale declines Empty eyes enslave the creations Of placid faces and lifeless pageants Dance with the dead in my dreams (Hello? Hello, Mr. Gein?) Listen to their hallowed screams (Mr. Gein?) The dead have taken my soul (let me out of here, Mr. Gein) Temptation's lost all control (Mr. Gein? I don't want to play anymore, Mr. Gein) Dance with the dead in my dreams (Mr. Gein, this isn't fun anymore) Listen to their hallowed screams (I don't wanna play anymore, Mr. Gein, Mr. Gein?) The dead have taken my soul (I want out of here, Mr. Gein) Temptation's lost all control (let me out now)\"\n",
        "print(estimate_genre(guesser, lyrics))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding covers:                            \n",
        "  What describes a cover?\n",
        "  + Action ? - a lot of static ones\n",
        "  + Presence of people ? - rather binary split\n",
        "  + Present items ? - weakly descriptive\n",
        "  \n",
        "  + Simplicity: complicated artwork vs bunch of people + text -> gives a nice hint\n",
        "  + Art style ?\n",
        "  + Mood ?\n",
        "  + Abstractness ?\n",
        "  + Modernicity ?"
      ],
      "metadata": {
        "id": "RQ45O2SRKu_V"
      }
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e68e4fe9624240eab1ec164d33083dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b10a2dccb87d4727af317eb95ebc3074",
              "IPY_MODEL_789dd1a095a147768a4dab65ebc89da9",
              "IPY_MODEL_43e176395c704439846e0d25c819f361"
            ],
            "layout": "IPY_MODEL_3107475876824820bce4cf8dfa619510"
          }
        },
        "b10a2dccb87d4727af317eb95ebc3074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_abbb6a8f8ca745c8bb8fb49d7ea67fd8",
            "placeholder": "​",
            "style": "IPY_MODEL_be643cc63bc44107b2571f5998e67583",
            "value": "Generating train split: "
          }
        },
        "789dd1a095a147768a4dab65ebc89da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5db2f60f6d584f71857fdf47e26f5b92",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60503fce0afb4947a57b0ed94f5fe985",
            "value": 1
          }
        },
        "43e176395c704439846e0d25c819f361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1aae315cdaa4636a95517fb891ffc30",
            "placeholder": "​",
            "style": "IPY_MODEL_c53ac40abb174b0da2a3a9528add5e62",
            "value": " 28372/0 [00:00&lt;00:00, 71935.12 examples/s]"
          }
        },
        "3107475876824820bce4cf8dfa619510": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abbb6a8f8ca745c8bb8fb49d7ea67fd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be643cc63bc44107b2571f5998e67583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5db2f60f6d584f71857fdf47e26f5b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "60503fce0afb4947a57b0ed94f5fe985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1aae315cdaa4636a95517fb891ffc30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c53ac40abb174b0da2a3a9528add5e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b83ffd7f55474ff5a1e221e86d97d364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e421048330e04f7a8ced3c8a0fa73c88",
              "IPY_MODEL_b456d48bc37e42ce92caa189acc0fb76",
              "IPY_MODEL_0d948bbeb0574a9892b785fe1e9b0956"
            ],
            "layout": "IPY_MODEL_151d353d3f4a49a4ace0c815c049b4ef"
          }
        },
        "e421048330e04f7a8ced3c8a0fa73c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a607b2dcb5804e8595a8a79682057706",
            "placeholder": "​",
            "style": "IPY_MODEL_aca3e69f8bef4f1f9db084838ec1dba4",
            "value": "Map: 100%"
          }
        },
        "b456d48bc37e42ce92caa189acc0fb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d9df7964443490286ed35ee8ea2f6c1",
            "max": 28372,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_354659732624407a81ea82b629987833",
            "value": 28372
          }
        },
        "0d948bbeb0574a9892b785fe1e9b0956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce3c35259ab34e78adac011215310ca8",
            "placeholder": "​",
            "style": "IPY_MODEL_76a9dbbc6a704bcca48ae2cc54cac493",
            "value": " 28372/28372 [00:01&lt;00:00, 17091.51 examples/s]"
          }
        },
        "151d353d3f4a49a4ace0c815c049b4ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a607b2dcb5804e8595a8a79682057706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aca3e69f8bef4f1f9db084838ec1dba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d9df7964443490286ed35ee8ea2f6c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354659732624407a81ea82b629987833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce3c35259ab34e78adac011215310ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76a9dbbc6a704bcca48ae2cc54cac493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}