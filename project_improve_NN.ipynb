{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_JSQ2q3IzLi",
        "outputId": "802c1406-a0c5-4957-826b-37c95b0c76c9",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.45.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.5.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
            "Requirement already satisfied: datashader in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from datashader) (3.1.0)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (from datashader) (2024.10.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader) (1.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from datashader) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from datashader) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datashader) (2.2.2)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader) (2.1.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from datashader) (11.0.0)\n",
            "Requirement already satisfied: pyct in /usr/local/lib/python3.10/dist-packages (from datashader) (0.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from datashader) (1.13.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from datashader) (0.12.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datashader) (24.2)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader) (2024.10.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (2024.9.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (6.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask->datashader) (8.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->datashader) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datashader) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datashader) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datashader) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->datashader) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->datashader) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->datashader) (2024.8.30)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask->datashader) (3.21.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask->datashader) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datashader) (1.16.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (3.6.1)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh) (1.26.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh) (24.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh) (2024.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh) (1.16.0)\n",
            "Requirement already satisfied: holoviews in /usr/local/lib/python3.10/dist-packages (1.20.0)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from holoviews) (3.6.1)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from holoviews) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from holoviews) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from holoviews) (24.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from holoviews) (2.2.2)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from holoviews) (1.5.4)\n",
            "Requirement already satisfied: param<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from holoviews) (2.1.1)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.10/dist-packages (from holoviews) (3.0.3)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (1.3.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->holoviews) (2024.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->holoviews) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->holoviews) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->holoviews) (2024.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (6.2.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (2.0.3)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (3.0.0)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (0.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->holoviews) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh>=3.1->holoviews) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3->holoviews) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->holoviews) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->holoviews) (1.0.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->holoviews) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->holoviews) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->holoviews) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->holoviews) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->panel>=1.0->holoviews) (2024.8.30)\n",
            "Requirement already satisfied: transformers==4.45.2 in /usr/local/lib/python3.10/dist-packages (4.45.2)\n",
            "Requirement already satisfied: sentence-transformers==3.1.1 in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.2) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.1.1) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.1.1) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.1.1) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers==3.1.1) (11.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.2) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.1.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.1.1) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers==3.1.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers==3.1.1) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.2) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==3.1.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers==3.1.1) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==3.1.1) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install  torch\n",
        "%pip install  transformers\n",
        "%pip install  accelerate\n",
        "%pip install  datasets\n",
        "%pip install  umap-learn\n",
        "%pip install  datashader\n",
        "%pip install  bokeh\n",
        "%pip install  holoviews\n",
        "%pip install transformers==4.45.2 sentence-transformers==3.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UG-NBViNt71W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89fbb3ae-b979-4a28-c770-43497742a532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/dufunc.py:343: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
            "  warnings.warn(msg, errors.NumbaWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/dufunc.py:343: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
            "  warnings.warn(msg, errors.NumbaWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/dufunc.py:343: NumbaWarning: Compilation requested for previously compiled argument types ((uint32,)). This has no effect and perhaps indicates a bug in the calling code (compiling a ufunc more than once for the same signature\n",
            "  warnings.warn(msg, errors.NumbaWarning)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datasets import load_dataset,Dataset, concatenate_datasets\n",
        "import numpy as np\n",
        "from time import process_time\n",
        "import math\n",
        "import random\n",
        "import joblib\n",
        "import umap\n",
        "import umap.plot\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from sentence_transformers import SentenceTransformer,SentenceTransformerTrainingArguments\n",
        "from sentence_transformers.losses import BatchAllTripletLoss, BatchHardSoftMarginTripletLoss, BatchHardTripletLoss\n",
        "from sentence_transformers.trainer import SentenceTransformerTrainer\n",
        "from sentence_transformers.training_args import BatchSamplers\n",
        "from sentence_transformers.evaluation import TripletEvaluator\n",
        "\n",
        "import torch\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk_besBpgPvp"
      },
      "source": [
        "### *EMBEDDER PART*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-T4t6Hp3qTps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e9e1b0-e2fb-43e7-8222-1b68f77d7a72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer(\"sentence-transformers/all-distilroberta-v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AQ5d2RUz_K5e"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"csv\", data_files=\"./tcc_ceds_music.csv\")\n",
        "dataset = dataset.remove_columns([\"artist_name\", \"track_name\"])\n",
        "dataset = dataset.rename_columns({\"genre\":\"label\", \"lyrics\":\"sentence\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9x3rM4Ia9kjn"
      },
      "outputs": [],
      "source": [
        "unique_genres = dataset['train'].unique('label')\n",
        "genre_to_index = {label: idx for idx, label in enumerate(unique_genres)}\n",
        "\n",
        "def label_to_index_func(data_set):\n",
        "    data_set['label'] = genre_to_index[data_set['label']]\n",
        "    return data_set\n",
        "\n",
        "dataset = dataset.map(label_to_index_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tQbwzIR4gPvq"
      },
      "outputs": [],
      "source": [
        "# populate with permuted lyrics\n",
        "n_songs_to_permute = len(dataset['train'])\n",
        "n_permutations = 4\n",
        "\n",
        "permuted_lyrics = []\n",
        "lables_of_permuted = []\n",
        "\n",
        "for i in range(n_songs_to_permute):\n",
        "    song_item = dataset['train'][i]\n",
        "    label = song_item['label']\n",
        "    sentence = song_item['sentence'].split(' ')\n",
        "\n",
        "    for ii in range(n_permutations):\n",
        "        permuted_song = \" \".join(random.sample(sentence, len(sentence)))\n",
        "        permuted_lyrics.append(permuted_song)\n",
        "        lables_of_permuted.append(label)\n",
        "\n",
        "permuted_dataset = Dataset.from_dict({\"sentence\":permuted_lyrics, \"label\":lables_of_permuted})\n",
        "dataset['train'] = concatenate_datasets([dataset['train'], permuted_dataset])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mKfvMC-ugPvq"
      },
      "outputs": [],
      "source": [
        "train_test_split = dataset['train'].train_test_split(test_size=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GAFDHUIwKaMO"
      },
      "outputs": [],
      "source": [
        "loss = BatchHardTripletLoss(model,margin=7)\n",
        "training_args = SentenceTransformerTrainingArguments(\n",
        "    output_dir=\"./models/guesser_2\",\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-6,\n",
        "    warmup_ratio=0.15,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.99,\n",
        "    weight_decay=0.01,\n",
        "    use_cpu=False,\n",
        "    fp16=True,  # Set to False if you get an error that your GPU can't run on FP16\n",
        "    bf16=False,  # Set to True if you have a GPU that supports BF16\n",
        "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
        "    # Optional tracking/debugging parameters:\n",
        "    save_steps=100,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=50,\n",
        "    seed=135)\n",
        "\n",
        "    # eval_strategy=\"steps\",\n",
        "    # eval_steps=100,\n",
        "    # save_strategy=\"steps\","
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8PB5MqoaEUro",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d7857923e4d34306b6b2ecae7c4a88ab",
            "35f5b1b559ad40f1a58437a2130c15f4",
            "2a699e0b2c75470cbd2cd3ca7db41906",
            "196acab1fd244472947e6b2bd126303f",
            "5341f040ca9a41188f37b48f116f61a4",
            "68623bbfb0414aa7b7a01ecd4d165dbb",
            "b3b0529a4a494a69a6f4de0dc21493bb",
            "a0ad189aa4b34a28b1687a01b96804b0",
            "41fa16f362f24da088ca7697b6f1f035",
            "201425c31328429cb9e761614800ba1d",
            "32dfe218c9d5444fb316da118c00ed09"
          ]
        },
        "outputId": "05c87fa3-f398-4852-a7e1-ec0684b8c191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myarish-pn\u001b[0m (\u001b[33myarish-pn-ukrainian-catholic-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241117_182517-m247jlnk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yarish-pn-ukrainian-catholic-university/sentence-transformers/runs/m247jlnk' target=\"_blank\">./models/guesser_2</a></strong> to <a href='https://wandb.ai/yarish-pn-ukrainian-catholic-university/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yarish-pn-ukrainian-catholic-university/sentence-transformers' target=\"_blank\">https://wandb.ai/yarish-pn-ukrainian-catholic-university/sentence-transformers</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yarish-pn-ukrainian-catholic-university/sentence-transformers/runs/m247jlnk' target=\"_blank\">https://wandb.ai/yarish-pn-ukrainian-catholic-university/sentence-transformers/runs/m247jlnk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1480' max='42115' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1480/42115 05:10 < 2:22:03, 4.77 it/s, Epoch 0.18/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>7.090900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>7.098900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>7.092600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>7.089100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>7.086600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>7.071300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>7.076600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>7.079400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>7.065700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>7.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>7.076000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>7.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>7.049200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>7.053500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>7.054000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>7.026400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>7.027800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>7.018000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>7.031100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>7.021900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>7.034400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>7.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>6.999800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>7.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>6.998000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>7.019300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>6.987800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>6.991400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>6.994300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7857923e4d34306b6b2ecae7c4a88ab"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5b65aef92f4b>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2052\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2053\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2391\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2392\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2393\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m                 ):\n\u001b[1;32m   2395\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_set = train_test_split['train']\n",
        "trainer = SentenceTransformerTrainer(\n",
        "    model=model,\n",
        "    train_dataset=train_set,\n",
        "    loss=loss,\n",
        "    args=training_args\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q010H_zeW5VY"
      },
      "outputs": [],
      "source": [
        "#save the embedding model\n",
        "model.save_pretrained(\"trained-embedder-permute\")\n",
        "! tar -czf trained_embedder.tar.gz ./trained-embedder-permute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kEpO0tbW5VX"
      },
      "outputs": [],
      "source": [
        "#creates test dataset to evaluate the embedder\n",
        "\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "class_groups = defaultdict(list)\n",
        "for example in train_test_split['test']:\n",
        "    class_groups[example['label']].append(example['sentence'])\n",
        "\n",
        "triplets = []\n",
        "\n",
        "for label, sentences in class_groups.items():\n",
        "    for i in range(len(sentences)):\n",
        "        for j in range(i + 1, len(sentences)):\n",
        "            anchor = sentences[i]\n",
        "            positive = sentences[j]\n",
        "\n",
        "            negative_label = random.choice([lbl for lbl in class_groups.keys() if lbl != label])\n",
        "            negative = random.choice(class_groups[negative_label])\n",
        "\n",
        "            triplets.append({\n",
        "                'anchor': anchor,\n",
        "                'positive': positive,\n",
        "                'negative': negative\n",
        "            })\n",
        "\n",
        "triplet_test_dataset = Dataset.from_list(triplets)\n",
        "triplet_test_dataset = triplet_test_dataset.shuffle(seed=83)\n",
        "\n",
        "print(triplet_test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkS5NdAXW5VY"
      },
      "outputs": [],
      "source": [
        "test_evaluator = TripletEvaluator(\n",
        "    anchors=triplet_test_dataset[\"anchor\"],\n",
        "    positives=triplet_test_dataset[\"positive\"],\n",
        "    negatives=triplet_test_dataset[\"negative\"],\n",
        "    name=\"all-test\",\n",
        ")\n",
        "print(test_evaluator(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7AvVv3AvlW6"
      },
      "outputs": [],
      "source": [
        "#load the saved embedding model\n",
        "! tar -xzf ./trained_embedder_permute.tar.gz ./\n",
        "model = SentenceTransformer(\"trained-embedder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qma2ILplQAsr"
      },
      "outputs": [],
      "source": [
        "def get_lyrics_embedding(lyrics:str):\n",
        "  return model.encode([lyrics.lower()])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = model.get_sentence_embedding_dimension()"
      ],
      "metadata": {
        "id": "nnZ5qxd6K867"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_NpIF9PgPvs"
      },
      "source": [
        "### *ESTIMATOR PART*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVG7byPW26_k"
      },
      "outputs": [],
      "source": [
        "#creates a dataframe of all songs as embeddings -> genre as idx\n",
        "\n",
        "lyrics_embeddigs = []\n",
        "genres = []\n",
        "unique_genres = set()\n",
        "\n",
        "import string\n",
        "songs_and_lyrics = pd.read_csv('./tcc_ceds_music.csv')\n",
        "\n",
        "for idx in range(len(songs_and_lyrics)):\n",
        "  genre = songs_and_lyrics[\"genre\"][idx]\n",
        "  unique_genres.add(genre)\n",
        "\n",
        "  lyrics_as_bag_of_words_string = str(songs_and_lyrics[\"lyrics\"][idx])\n",
        "\n",
        "  embedding =  get_lyrics_embedding(lyrics_as_bag_of_words_string)[0]\n",
        "  lyrics_embeddigs.append(embedding)\n",
        "  genres.append(genre)\n",
        "\n",
        "embedding_set = pd.DataFrame({\"genres\":genres})\n",
        "embeddings_list = []\n",
        "\n",
        "for i in range(embedding_size):\n",
        "  dim_i = pd.Series([embedding[i] for embedding in lyrics_embeddigs])\n",
        "  embeddings_list.append(dim_i)\n",
        "\n",
        "embeddings_df = pd.concat(embeddings_list, axis=1)\n",
        "embedding_set = pd.concat([embeddings_df, embedding_set], axis=1)\n",
        "\n",
        "embedding_set['genres'] = embedding_set['genres'].apply(lambda genre: genre_to_index[genre])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFRKJwszev8_"
      },
      "outputs": [],
      "source": [
        "#save embeddings of all songs\n",
        "joblib.dump(embedding_set, \"embedding_set_of_all_songs_permute.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "PJi4jq9DhbpG"
      },
      "outputs": [],
      "source": [
        "#load the embeddigns of al songs\n",
        "embedding_set = joblib.load(\"embedding_set_of_all_songs_permute.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ifReduceDimensionality = False\n",
        "reductionFactor = 2\n",
        "metric = 'euclidean'\n",
        "\n",
        "ifPlotReduced = False\n",
        "\n",
        "if ifPlotReduced:\n",
        "  actual_embedding_set = embedding_set.iloc[:, :-1]\n",
        "\n",
        "  dim_reducer = umap.UMAP( n_neighbors=5,\n",
        "        min_dist=0.2,\n",
        "        n_components=2,\n",
        "        metric=metric\n",
        "  )\n",
        "  pure_reductions = dim_reducer.fit(actual_embedding_set)\n",
        "  umap.plot.points(pure_reductions, labels=np.array([unique_genres[i] for i in embedding_set['genres']]), theme='green', show_legend=True)\n",
        "\n",
        "if ifReduceDimensionality:\n",
        "  actual_embedding_set = embedding_set.iloc[:, :-1]\n",
        "\n",
        "  embedding_size_reduced = int(embedding_size / reductionFactor)\n",
        "\n",
        "  dim_reducer = umap.UMAP( n_neighbors=10,\n",
        "        min_dist=0.15,\n",
        "        n_components=embedding_size_reduced,\n",
        "        metric=metric\n",
        "  )\n",
        "  reduced_embeddings = pd.DataFrame(dim_reducer.fit_transform(actual_embedding_set), columns = [i for i in range(embedding_size_reduced)])\n",
        "  print(reduced_embeddings.shape)\n",
        "  reduced_embeddings['genres'] = embedding_set['genres']\n",
        "\n",
        "  embedding_size = embedding_size_reduced\n",
        "  embedding_set = reduced_embeddings\n",
        "  print(reduced_embeddings.head(15))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSEg2eWubnMT",
        "outputId": "dd7fec2b-cbb4-46c5-ec2f-4c6a722823bc"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(28372, 384)\n",
            "           0          1         2         3         4         5         6  \\\n",
            "0   0.006657   9.985072  0.116298  0.385394  9.798559  9.888879  9.759837   \n",
            "1   0.020167   9.926363  0.120915  0.444864  9.823700  9.721794  9.825130   \n",
            "2   0.002221   9.983907  0.105028  0.320600  9.797009  9.812377  9.689634   \n",
            "3  -0.009119  10.025797  0.123029  0.496026  9.743014  9.830189  9.754365   \n",
            "4   0.026327   9.921905  0.116629  0.353378  9.816274  9.781140  9.795197   \n",
            "5   0.041143   9.991891  0.102127  0.389756  9.792583  9.803241  9.811359   \n",
            "6  -0.017765   9.967948  0.035618  0.351478  9.830951  9.790486  9.822804   \n",
            "7   0.042228   9.956791  0.122126  0.329469  9.823695  9.820170  9.755121   \n",
            "8  -0.007651   9.931602  0.090921  0.348262  9.791393  9.816966  9.859863   \n",
            "9   0.059862   9.838399  0.026189  0.363530  9.890288  9.629166  9.854910   \n",
            "10 -0.045023   9.938864  0.054923  0.377482  9.802763  9.808183  9.831638   \n",
            "11  0.000272   9.907283  0.080225  0.342542  9.815277  9.793071  9.869631   \n",
            "12 -0.016003   9.969202  0.130647  0.400007  9.771405  9.826211  9.791510   \n",
            "13 -0.030050   9.954472  0.026446  0.318561  9.836522  9.732436  9.844921   \n",
            "14  0.013880   9.933648  0.084252  0.354618  9.803929  9.774328  9.864490   \n",
            "\n",
            "           7         8         9  ...       375       376       377       378  \\\n",
            "0   3.213539  9.587258  7.859389  ...  5.564691  4.956853  4.983468  5.821056   \n",
            "1   2.744164  9.467409  7.908217  ...  5.564050  4.938927  4.966753  5.890534   \n",
            "2   2.724740  9.443475  7.935818  ...  5.578927  4.978498  4.992691  5.856624   \n",
            "3   3.927905  9.879980  7.673723  ...  5.554191  4.932123  4.903999  5.907504   \n",
            "4   2.465635  9.360839  8.034515  ...  5.585090  4.965484  4.988142  5.835545   \n",
            "5   3.308099  9.658140  7.841327  ...  5.555057  4.980308  4.925138  5.872149   \n",
            "6   3.076865  9.610456  7.864701  ...  5.540853  4.965946  4.948960  5.886515   \n",
            "7   2.437804  9.357241  8.060240  ...  5.578360  4.978457  4.960882  5.822062   \n",
            "8   3.276735  9.654703  7.800253  ...  5.576091  4.969879  4.927576  5.895611   \n",
            "9   1.540212  9.051620  8.116976  ...  5.571358  4.969868  5.051650  5.804410   \n",
            "10  3.541337  9.764622  7.771775  ...  5.523338  4.915253  4.891925  5.916080   \n",
            "11  2.825906  9.504670  7.884529  ...  5.580692  4.973194  4.953219  5.873048   \n",
            "12  3.488983  9.710570  7.783902  ...  5.568777  4.949566  4.963823  5.890377   \n",
            "13  2.913111  9.568806  7.834921  ...  5.546719  4.974891  4.918770  5.890428   \n",
            "14  3.140887  9.610886  7.828066  ...  5.574496  4.974407  4.931405  5.892969   \n",
            "\n",
            "         379       380       381       382       383  genres  \n",
            "0   4.025554  4.542914  4.966296  4.503353  5.275563       0  \n",
            "1   3.997380  4.613729  4.965477  4.554691  5.299809       0  \n",
            "2   4.000577  4.587167  4.956057  4.539465  5.286342       0  \n",
            "3   4.042805  4.540967  4.965848  4.544877  5.268611       0  \n",
            "4   4.009031  4.595650  4.950078  4.536319  5.302364       0  \n",
            "5   4.015401  4.586599  4.971856  4.529084  5.280323       0  \n",
            "6   4.005541  4.588041  4.966435  4.526183  5.276152       0  \n",
            "7   3.995348  4.596617  4.960381  4.529964  5.302305       0  \n",
            "8   4.034137  4.581072  4.967593  4.543515  5.294585       0  \n",
            "9   3.978351  4.675215  4.938776  4.533391  5.318951       0  \n",
            "10  4.039337  4.572228  4.972004  4.537530  5.290503       0  \n",
            "11  4.021218  4.601592  4.956602  4.540835  5.302517       0  \n",
            "12  4.043991  4.557817  4.957930  4.538626  5.290534       0  \n",
            "13  3.991522  4.632906  4.966100  4.527167  5.285547       0  \n",
            "14  4.029105  4.594699  4.969236  4.545769  5.294793       0  \n",
            "\n",
            "[15 rows x 385 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "pEIE7rbAybpD"
      },
      "outputs": [],
      "source": [
        "batch_size = 4\n",
        "#transforms the training embedding data into torch-compliant format\n",
        "\n",
        "features = embedding_set.iloc[:, :-1].values\n",
        "labels = embedding_set.iloc[:, -1].values\n",
        "sparse_labels = []\n",
        "for genre_label in labels:\n",
        "  sparse_arr = [0 for i in range(len(unique_genres))]\n",
        "  sparse_arr[genre_label] = 1\n",
        "  sparse_labels.append(sparse_arr)\n",
        "\n",
        "features_tensor = torch.tensor(features, dtype=torch.float32)\n",
        "labels_tensor = torch.tensor(sparse_labels, dtype=torch.float32)\n",
        "\n",
        "dataset_train = torch.utils.data.TensorDataset(features_tensor, labels_tensor)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#transforms the testing embedding data into torch-compliant format\n",
        "\n",
        "test_size = 8000\n",
        "rand_indices = np.random.randint(0, len(embedding_set), size=test_size)\n",
        "\n",
        "features = embedding_set.iloc[rand_indices, :-1].values\n",
        "labels = embedding_set.iloc[rand_indices, -1].values\n",
        "\n",
        "features_tensor = torch.tensor(features, dtype=torch.float32)\n",
        "labels_tensor = torch.tensor(labels, dtype=torch.int32)\n",
        "\n",
        "dataset_test = torch.utils.data.TensorDataset(features_tensor, labels_tensor)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "7YHVTHoO1TAs"
      },
      "outputs": [],
      "source": [
        "#the nn used for genre estimation\n",
        "\n",
        "class NeuralGuesser40Conv(nn.Module):\n",
        "    def __init__(self, embedding_size:int):\n",
        "        super().__init__()\n",
        "        self.num_conv_output_channels = 3\n",
        "\n",
        "        self.pre_conv1 = nn.Conv1d(1,self.num_conv_output_channels,7,stride=1,padding=\"same\")\n",
        "        self.prelu_weights = nn.Parameter(torch.ones(self.num_conv_output_channels))\n",
        "\n",
        "        # self.layer0 = nn.Linear(int(embedding_size), int(embedding_size/2))\n",
        "\n",
        "        self.layer0 = nn.Linear(int(embedding_size * self.num_conv_output_channels), int(embedding_size/2))\n",
        "        self.layer1 = nn.Linear(int(embedding_size/2), int(embedding_size/3))\n",
        "        # self.layerExp = nn.Linear(int(embedding_size/3), embedding_size)\n",
        "        self.layer2 = nn.Linear(int(embedding_size/3), int(embedding_size/6))\n",
        "        self.layer3 = nn.Linear(int(embedding_size/6), int(embedding_size/12))\n",
        "\n",
        "        self.layer4 = nn.Linear(int(embedding_size/12), len(unique_genres))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.prelu(self.pre_conv1(x), self.prelu_weights)\n",
        "        x = torch.flatten(x,1)\n",
        "\n",
        "        x = F.relu(self.layer0(x))\n",
        "        x = F.relu(self.layer1(x))\n",
        "        # x = F.relu(self.layerExp(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = F.relu(self.layer3(x))\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# class NeuralGuesser50Linear(nn.Module):\n",
        "#     def __init__(self, embedding_size:int):\n",
        "#         super().__init__()\n",
        "\n",
        "#         self.layer0 = nn.Linear(int(embedding_size), int(embedding_size/2))\n",
        "\n",
        "#         self.layer1 = nn.Linear(int(embedding_size/2), int(embedding_size/3))\n",
        "#         self.layer2 = nn.Linear(int(embedding_size/3), int(embedding_size/6))\n",
        "#         self.layer3 = nn.Linear(int(embedding_size/6), int(embedding_size/12))\n",
        "\n",
        "#         self.layer4 = nn.Linear(int(embedding_size/12), len(unique_genres))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.layer0(x))\n",
        "#         x = F.relu(self.layer1(x))\n",
        "#         x = F.relu(self.layer2(x))\n",
        "#         x = F.relu(self.layer3(x))\n",
        "#         x = self.layer4(x)\n",
        "\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsIqJdF0AUCa",
        "outputId": "be5556de-685d-4c8e-fbb0-dedfb99a6949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean loss for [1,   500] : 1.874\n",
            "Mean loss for [1,  1000] : 1.835\n",
            "Mean loss for [1,  1500] : 1.845\n",
            "Mean loss for [1,  2000] : 1.847\n",
            "Mean loss for [1,  2500] : 1.842\n",
            "Mean loss for [1,  3000] : 1.842\n",
            "Mean loss for [1,  3500] : 1.831\n",
            "Mean loss for [1,  4000] : 1.821\n",
            "Mean loss for [1,  4500] : 1.825\n",
            "Mean loss for [1,  5000] : 1.813\n",
            "Mean loss for [1,  5500] : 1.808\n",
            "Mean loss for [1,  6000] : 1.792\n",
            "Mean loss for [1,  6500] : 1.812\n",
            "Mean loss for [1,  7000] : 1.806\n",
            "Mean loss for [2,   500] : 1.820\n",
            "Mean loss for [2,  1000] : 1.795\n",
            "Mean loss for [2,  1500] : 1.811\n",
            "Mean loss for [2,  2000] : 1.783\n",
            "Mean loss for [2,  2500] : 1.786\n",
            "Mean loss for [2,  3000] : 1.795\n",
            "Mean loss for [2,  3500] : 1.796\n",
            "Mean loss for [2,  4000] : 1.811\n",
            "Mean loss for [2,  4500] : 1.787\n",
            "Mean loss for [2,  5000] : 1.776\n",
            "Mean loss for [2,  5500] : 1.804\n",
            "Mean loss for [2,  6000] : 1.785\n",
            "Mean loss for [2,  6500] : 1.798\n",
            "Mean loss for [2,  7000] : 1.793\n",
            "Mean loss for [3,   500] : 1.780\n",
            "Mean loss for [3,  1000] : 1.788\n",
            "Mean loss for [3,  1500] : 1.788\n",
            "Mean loss for [3,  2000] : 1.796\n",
            "Mean loss for [3,  2500] : 1.805\n",
            "Mean loss for [3,  3000] : 1.809\n",
            "Mean loss for [3,  3500] : 1.778\n",
            "Mean loss for [3,  4000] : 1.810\n",
            "Mean loss for [3,  4500] : 1.803\n",
            "Mean loss for [3,  5000] : 1.778\n",
            "Mean loss for [3,  5500] : 1.784\n",
            "Mean loss for [3,  6000] : 1.786\n",
            "Mean loss for [3,  6500] : 1.792\n",
            "Mean loss for [3,  7000] : 1.801\n"
          ]
        }
      ],
      "source": [
        "#training the nn\n",
        "\n",
        "guesser = NeuralGuesser40Conv(embedding_size)\n",
        "loss_alg = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(guesser.parameters(), lr=0.001, betas=(0.9, 0.99))\n",
        "\n",
        "for epoch in range(3):\n",
        "\n",
        "    current_loss = 0.0\n",
        "\n",
        "    for i, data in enumerate(train_data_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs[:,None,:] #adding a dimension to be able to feed it through convolution\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = guesser(inputs)\n",
        "        loss = loss_alg(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        current_loss += loss.item()\n",
        "        if i % 500 == 499:\n",
        "            print(f'Mean loss for [{epoch + 1}, {i + 1:5d}] : {current_loss / 500:.3f}')\n",
        "            current_loss = 0.0\n",
        "\n",
        "torch.save(guesser.state_dict(), \"./trained-nn.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "satthA5pdnmB",
        "outputId": "984ea169-f929-4571-a587-dc55e65839a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for 8000 test lyrics: 25 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_data_loader:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs[:,None,:] #adding a dimension to be able to feed it through convolution\n",
        "        outputs = guesser(inputs)\n",
        "\n",
        "        value, predicted_classes = torch.max(outputs.data, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted_classes == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy for 8000 test lyrics: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *INPUT LYRICS PROCESSING PART*"
      ],
      "metadata": {
        "id": "g0uQuWCpa-PO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EHMrwu4PdXq",
        "outputId": "efc89be0-8a6a-4e68-b05e-ab18cfa203c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "%pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer as wnl\n",
        "import string\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('tagsets')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGXn5FAiC7vR"
      },
      "outputs": [],
      "source": [
        "part_of_speech_mapper = {\n",
        "    'NN': 'n', 'NNS': 'n', 'NNP': 'n', 'NNPS': 'n',\n",
        "    'VB': 'v', 'VBD': 'v', 'VBG': 'v', 'VBN': 'v', 'VBP': 'v', 'VBZ': 'v',\n",
        "    'JJ': 'a', 'JJR': 'a', 'JJS': 'a',\n",
        "    'RB': 'r', 'RBR': 'r', 'RBS': 'r',\n",
        "    'PDT': 'a',\n",
        "    'WRB': 'r',\n",
        "    '$': None, \"''\": None, '(': None, ')': None, ',': None, '--': None, '.': None,\n",
        "    ':': None, 'CC': None, 'CD': None, 'DT': None, 'EX': None, 'FW': None, 'IN': None,\n",
        "    'LS': None, 'MD': None, 'POS': None, 'PRP': None, 'PRP$': None, 'RP': None,\n",
        "    'SYM': None, 'TO': None, 'UH': None, 'WDT': None, 'WP': None, 'WP$': None,\n",
        "    '``': None,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgVk6T3Uah64"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "symbols = set([\",\",\".\",\"/\",\"#\",\"*\",\"(\",\")\",\"?\",\"+\",\"=\",\":\",\";\",\"%\",\"[\", \"]\"])\n",
        "song_specific = set([\"chorus\", \"repeat\", \"verse\", \"oh\", \"ooh\", \"ah\", \"aah\"])\n",
        "\n",
        "def check_if_not_to_be_removed(token:str):\n",
        "  return (not token.lower() in stop_words) and (not token.lower() in symbols) and (not token.lower() in song_specific) and (not any(char.isdigit() for char in token)) and (not \"'\" in token)\n",
        "\n",
        "def transform_lyrics(lyrics:str):\n",
        "  tokenized_lyrics = word_tokenize(lyrics)\n",
        "\n",
        "  tagged_lyrics = nltk.pos_tag(tokenized_lyrics)\n",
        "  lemmatized_lyrics = [wnl().lemmatize(word.lower(), pos=part_of_speech_mapper[assumed_pos]) for word,assumed_pos in tagged_lyrics if part_of_speech_mapper[assumed_pos] != None]\n",
        "  filtered_lyrics = [w.lower() for w in lemmatized_lyrics if check_if_not_to_be_removed(w)]\n",
        "\n",
        "  deduplicated_lyrics = \"\"\n",
        "  last_word = \"\"\n",
        "  for word in filtered_lyrics:\n",
        "    if word != last_word:\n",
        "      deduplicated_lyrics += f\"{word} \"\n",
        "      last_word = word\n",
        "\n",
        "  print(\"Tokenized lyrics:\", ' '.join(tokenized_lyrics))\n",
        "  print(\"Lemmatized lyrics:\", ' '.join(lemmatized_lyrics))\n",
        "  print(\"Transformed lyrics:\", deduplicated_lyrics)\n",
        "\n",
        "  return deduplicated_lyrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8RyFbtXa7ya"
      },
      "outputs": [],
      "source": [
        "def estimate_genre(model, song_lyrics):\n",
        "  filtered_lyrics = transform_lyrics(song_lyrics)\n",
        "\n",
        "  embedding = get_lyrics_embedding(filtered_lyrics)\n",
        "  model_prompt = torch.tensor(embedding, dtype=torch.float32)[:,None,:] #only if using convolutional layer\n",
        "\n",
        "  #get estimate here\n",
        "  prediction = model(model_prompt)\n",
        "\n",
        "  value, genre = torch.max(prediction, 1)\n",
        "\n",
        "  #map to the actual genre\n",
        "  for key,item in genre_to_index.items():\n",
        "    if genre == item:\n",
        "      return key\n",
        "\n",
        "  return -1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### *EXPERIMENTS PART*"
      ],
      "metadata": {
        "id": "x_RC3YHUbGYK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN4g-Xe0bilE",
        "outputId": "ef5f18c7-0996-425e-84fd-05fd9a3a10c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized lyrics: Ooh You can dance You can jive Having the time of your life Ooh , see that girl Watch that scene Digging the dancing queen Friday night and the lights are low Looking out for a place to go Where they play the right music Getting in the swing You come to look for a king Anybody could be that guy Night is young and the music 's high With a bit of rock music Everything is fine You 're in the mood for a dance And when you get the chance You are the dancing queen Young and sweet Only seventeen Dancing queen Feel the beat from the tambourine , oh yeah You can dance You can jive Having the time of your life Ooh , see that girl Watch that scene Digging the dancing queen You 're a teaser , you turn 'em on Leave 'em burning and then you 're gone Looking out for another Anyone will do You 're in the mood for a dance And when you get the chance You are the dancing queen Young and sweet Only seventeen Dancing queen Feel the beat from the tambourine , oh yeah You can dance You can jive Having the time of your life Ooh , see that girl Watch that scene Digging the dancing queen Digging the dancing queen\n",
            "Lemmatized lyrics: dance jive have time life ooh see girl watch scene dig dance queen friday night light be low look place go where play right music get swing come look king anybody be guy night be young music high bit rock music everything be fine 're mood dance when get chance be dance queen young sweet only seventeen dance queen feel beat tambourine dance jive have time life ooh see girl watch scene dig dance queen 're teaser turn leave 'em burning then 're go look anyone do 're mood dance when get chance be dance queen young sweet only seventeen dance queen feel beat tambourine dance jive have time life ooh see girl watch scene dig dance queen dig dancing queen\n",
            "Transformed lyrics: dance jive time life see girl watch scene dig dance queen friday night light low look place go play right music get swing come look king anybody guy night young music high bit rock music everything fine mood dance get chance dance queen young sweet seventeen dance queen feel beat tambourine dance jive time life see girl watch scene dig dance queen teaser turn leave burning go look anyone mood dance get chance dance queen young sweet seventeen dance queen feel beat tambourine dance jive time life see girl watch scene dig dance queen dig dancing queen \n",
            "pop\n"
          ]
        }
      ],
      "source": [
        "lyrics=\"Ooh You can dance You can jive Having the time of your life Ooh, see that girl Watch that scene Digging the dancing queen Friday night and the lights are low Looking out for a place to go Where they play the right music Getting in the swing You come to look for a king Anybody could be that guy Night is young and the music's high With a bit of rock music Everything is fine You're in the mood for a dance And when you get the chance You are the dancing queen Young and sweet Only seventeen Dancing queen Feel the beat from the tambourine, oh yeah You can dance You can jive Having the time of your life Ooh, see that girl Watch that scene Digging the dancing queen You're a teaser, you turn 'em on Leave 'em burning and then you're gone Looking out for another Anyone will do You're in the mood for a dance And when you get the chance You are the dancing queen Young and sweet Only seventeen Dancing queen Feel the beat from the tambourine, oh yeah You can dance You can jive Having the time of your life Ooh, see that girl Watch that scene Digging the dancing queen Digging the dancing queen\"\n",
        "print(estimate_genre(guesser, lyrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNs-Uo6He_rE",
        "outputId": "5cb487c1-7ecb-4be4-9dd3-39b492b80545"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized lyrics: Half past twelve And I 'm watchin ' the late show in my flat , all alone How I hate to spend the evening on my own Autumn winds Blowin ' outside the window as I look around the room And it makes me so depressed to see the gloom There 's not a soul out there No one to hear my prayer Gim me , gim me , gim me a man after midnight Wo n't somebody help me chase these shadows away ? Gim me , gim me , gim me a man after midnight Take me through the darkness to the break of the day Movie stars Find the end of the rainbow with a fortune to win It 's so different from the world I 'm living in Tired of TV I open the window and I gaze into the night But there 's nothing there to see , no one in sight There 's not a soul out there No one to hear my prayer Gim me , gim me , gim me a man after midnight Wo n't somebody help me chase these shadows away ? Gim me , gim me , gim me a man after midnight Take me through the darkness to the break of the day Gim me , gim me , gim me a man after midnight Gim me , gim me , gim me a man after midnight There 's not a soul out there No one to hear my prayer Gim me , gim me , gim me a man after midnight Wo n't somebody help me chase these shadows away ? Gim me , gim me , gim me a man after midnight Take me through the darkness to the break of the day Gim me , gim me , gim me a man after midnight Wo n't somebody help me chase these shadows away ? Gim me , gim me , gim me a man after midnight Take me through the darkness to the break of the day\n",
            "Lemmatized lyrics: half past twelve 'm watchin late show flat alone how hate spend evening own autumn wind blowin window look room make so depress see gloom 's not soul there one hear prayer gim gim gim man midnight wo n't somebody help chase shadow gim gim gim man midnight take darkness break day movie star end rainbow fortune win 's so different world 'm live tired tv open window gaze night 's nothing there see one sight 's not soul there one hear prayer gim gim gim man midnight wo n't somebody help chase shadow gim gim gim man midnight take darkness break day gim gim gim man midnight gim gim gim man midnight 's not soul there one hear prayer gim gim gim man midnight wo n't somebody help chase shadow gim gim gim man midnight take darkness break day gim gim gim man midnight wo n't somebody help chase shadow gim gim gim man midnight take darkness break day\n",
            "Transformed lyrics: half past twelve watchin late show flat alone hate spend evening autumn wind blowin window look room make depress see gloom soul one hear prayer gim man midnight wo somebody help chase shadow gim man midnight take darkness break day movie star end rainbow fortune win different world live tired tv open window gaze night nothing see one sight soul one hear prayer gim man midnight wo somebody help chase shadow gim man midnight take darkness break day gim man midnight gim man midnight soul one hear prayer gim man midnight wo somebody help chase shadow gim man midnight take darkness break day gim man midnight wo somebody help chase shadow gim man midnight take darkness break day \n",
            "pop\n"
          ]
        }
      ],
      "source": [
        "lyrics=\"Half past twelve And I'm watchin' the late show in my flat, all alone How I hate to spend the evening on my own Autumn winds Blowin' outside the window as I look around the room And it makes me so depressed to see the gloom There's not a soul out there No one to hear my prayer Gimme, gimme, gimme a man after midnight Won't somebody help me chase these shadows away? Gimme, gimme, gimme a man after midnight Take me through the darkness to the break of the day Movie stars Find the end of the rainbow with a fortune to win It's so different from the world I'm living in Tired of TV I open the window and I gaze into the night But there's nothing there to see, no one in sight There's not a soul out there No one to hear my prayer Gimme, gimme, gimme a man after midnight Won't somebody help me chase these shadows away? Gimme, gimme, gimme a man after midnight Take me through the darkness to the break of the day Gimme, gimme, gimme a man after midnight Gimme, gimme, gimme a man after midnight There's not a soul out there No one to hear my prayer Gimme, gimme, gimme a man after midnight Won't somebody help me chase these shadows away? Gimme, gimme, gimme a man after midnight Take me through the darkness to the break of the day Gimme, gimme, gimme a man after midnight Won't somebody help me chase these shadows away? Gimme, gimme, gimme a man after midnight Take me through the darkness to the break of the day\"\n",
        "print(estimate_genre(guesser, lyrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wydBqDgP8Ibu",
        "outputId": "bc89d1ec-137b-4137-f16e-9451425a22d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized lyrics: You 'll take my life but I 'll take yours , too You 'll fire your musket but I 'll run you through So when you 're waiting for the next attack You 'd better stand , there 's no turning back The bugle sounds , the charge begins But on this battlefield , no one wins The smell of acrid smoke and horses ' breath As I plunge on into certain death Oh Oh The horse he sweats with fear , we break to run The mighty roar of the Russian guns And as we race towards the human wall The screams of pain as my comrades fall We hurdle bodies that lay on the ground And the Russians fire another round We get so near yet so far away We wo n't live to fight another day Oh Oh We get so close , near enough to fight When a Russian gets me in his sights He pulls the trigger and I feel the blow A burst of rounds take my horse below And as I lay there gazing at the sky My body 's numb and my throat is dry And as I lay forgotten and alone Without a tear I draw my parting groan Oh Oh\n",
            "Lemmatized lyrics: take life take yours too fire musket run so when 're wait next attack good stand 's turn bugle sound charge begin battlefield one win smell acrid smoke horse breath plunge certain death oh oh horse sweat fear break run mighty roar russian gun race human wall scream pain comrade fall hurdle body lay ground russian fire round get so near yet so far away n't live fight day oh oh get so close enough fight when russian get sight pull trigger feel blow burst round take horse below lay there gaze sky my body numb throat be dry lay forgotten alone tear draw parting groan oh oh\n",
            "Transformed lyrics: take life take fire musket run wait next attack good stand turn bugle sound charge begin battlefield one win smell acrid smoke horse breath plunge certain death horse sweat fear break run mighty roar russian gun race human wall scream pain comrade fall hurdle body lay ground russian fire round get near yet far away live fight day get close enough fight russian get sight pull trigger feel blow burst round take horse lay gaze sky body numb throat dry lay forgotten alone tear draw parting groan \n",
            "pop\n"
          ]
        }
      ],
      "source": [
        "lyrics=\"You'll take my life but I'll take yours, too You'll fire your musket but I'll run you through So when you're waiting for the next attack You'd better stand, there's no turning back The bugle sounds, the charge begins But on this battlefield, no one wins The smell of acrid smoke and horses' breath As I plunge on into certain death Oh Oh The horse he sweats with fear, we break to run The mighty roar of the Russian guns And as we race towards the human wall The screams of pain as my comrades fall We hurdle bodies that lay on the ground And the Russians fire another round We get so near yet so far away We won't live to fight another day Oh Oh We get so close, near enough to fight When a Russian gets me in his sights He pulls the trigger and I feel the blow A burst of rounds take my horse below And as I lay there gazing at the sky My body's numb and my throat is dry And as I lay forgotten and alone Without a tear I draw my parting groan Oh Oh\"\n",
        "print(estimate_genre(guesser, lyrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBGhWbBvgPvt",
        "outputId": "5bcbb12d-3e1b-4a22-d419-3bf7a4c7ccb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized lyrics: How I 've waited for you to come I 've been here all alone Now that you 've arrived Please stay awhile And I promise I wo n't keep you long I 'll keep you forever ( forever , forever , forever ) Graze the skin with my fingertips The brush of dead , cold flesh appease the means Provoking images , delicate features so smooth A pleasant fragrance in the light of the moon Dance with the dead in my dreams Listen to their hallowed screams The dead have taken my soul Temptation 's lost all control Simple smiles elude psychotic eyes Lose all mind control , rationale declines Empty eyes enslave the creations Of placid faces and lifeless pageants In the depths of a mind insane Fantasy and reality are the same Graze the skin with my fingertips The brush of dead , warm flesh pacifies the means Incised members ornaments on my being Adulating the skin before me Simple smiles elude psychotic eyes Lose all mind control , rationale declines Empty eyes enslave the creations Of placid faces and lifeless pageants Dance with the dead in my dreams ( Hello ? Hello , Mr . Gein ? ) Listen to their hallowed screams ( Mr . Gein ? ) The dead have taken my soul ( let me out of here , Mr. Gein ) Temptation 's lost all control ( Mr. Gein ? I do n't want to play anymore , Mr. Gein ) Dance with the dead in my dreams ( Mr. Gein , this is n't fun anymore ) Listen to their hallowed screams ( I do n't wan na play anymore , Mr. Gein , Mr . Gein ? ) The dead have taken my soul ( I want out of here , Mr. Gein ) Temptation 's lost all control ( let me out now )\n",
            "Lemmatized lyrics: how 've wait come 've be here alone now 've arrive please stay promise n't keep long keep forever forever forever forever graze skin fingertip brush dead cold flesh appease mean provoking image delicate feature so smooth a pleasant fragrance light moon dance dead dream listen hallow scream dead have take soul temptation lost control simple smile elude psychotic eye lose mind control rationale decline empty eye enslave creation placid face lifeless pageant depth mind insane fantasy reality be same graze skin fingertip brush dead warm flesh pacify mean incise member ornament be adulate skin simple smile elude psychotic eye lose mind control rationale decline empty eye enslave creation placid face lifeless pageant dance dead dream hello hello mr gein listen hallow scream mr gein dead have take soul let here mr. gein temptation lost control mr. gein do n't want play anymore mr. gein dance dead dream mr. gein be n't fun anymore listen hallow scream do n't wan na play anymore mr. gein mr gein dead have take soul want here mr. gein temptation lost control let now\n",
            "Transformed lyrics: wait come alone arrive please stay promise keep long keep forever graze skin fingertip brush dead cold flesh appease mean provoking image delicate feature smooth pleasant fragrance light moon dance dead dream listen hallow scream dead take soul temptation lost control simple smile elude psychotic eye lose mind control rationale decline empty eye enslave creation placid face lifeless pageant depth mind insane fantasy reality graze skin fingertip brush dead warm flesh pacify mean incise member ornament adulate skin simple smile elude psychotic eye lose mind control rationale decline empty eye enslave creation placid face lifeless pageant dance dead dream hello mr gein listen hallow scream mr gein dead take soul let mr. gein temptation lost control mr. gein want play anymore mr. gein dance dead dream mr. gein fun anymore listen hallow scream wan na play anymore mr. gein mr gein dead take soul want mr. gein temptation lost control let \n",
            "pop\n"
          ]
        }
      ],
      "source": [
        "lyrics=\"How I've waited for you to come I've been here all alone Now that you've arrived Please stay awhile And I promise I won't keep you long I'll keep you forever (forever, forever, forever) Graze the skin with my fingertips The brush of dead, cold flesh appease the means Provoking images, delicate features so smooth A pleasant fragrance in the light of the moon Dance with the dead in my dreams Listen to their hallowed screams The dead have taken my soul Temptation's lost all control Simple smiles elude psychotic eyes Lose all mind control, rationale declines Empty eyes enslave the creations Of placid faces and lifeless pageants In the depths of a mind insane Fantasy and reality are the same Graze the skin with my fingertips The brush of dead, warm flesh pacifies the means Incised members ornaments on my being Adulating the skin before me Simple smiles elude psychotic eyes Lose all mind control, rationale declines Empty eyes enslave the creations Of placid faces and lifeless pageants Dance with the dead in my dreams (Hello? Hello, Mr. Gein?) Listen to their hallowed screams (Mr. Gein?) The dead have taken my soul (let me out of here, Mr. Gein) Temptation's lost all control (Mr. Gein? I don't want to play anymore, Mr. Gein) Dance with the dead in my dreams (Mr. Gein, this isn't fun anymore) Listen to their hallowed screams (I don't wanna play anymore, Mr. Gein, Mr. Gein?) The dead have taken my soul (I want out of here, Mr. Gein) Temptation's lost all control (let me out now)\"\n",
        "print(estimate_genre(guesser, lyrics))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d7857923e4d34306b6b2ecae7c4a88ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_35f5b1b559ad40f1a58437a2130c15f4",
              "IPY_MODEL_2a699e0b2c75470cbd2cd3ca7db41906",
              "IPY_MODEL_196acab1fd244472947e6b2bd126303f"
            ],
            "layout": "IPY_MODEL_5341f040ca9a41188f37b48f116f61a4"
          }
        },
        "35f5b1b559ad40f1a58437a2130c15f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68623bbfb0414aa7b7a01ecd4d165dbb",
            "placeholder": "",
            "style": "IPY_MODEL_b3b0529a4a494a69a6f4de0dc21493bb",
            "value": "Computingwidgetexamples:100%"
          }
        },
        "2a699e0b2c75470cbd2cd3ca7db41906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ad189aa4b34a28b1687a01b96804b0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41fa16f362f24da088ca7697b6f1f035",
            "value": 1
          }
        },
        "196acab1fd244472947e6b2bd126303f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_201425c31328429cb9e761614800ba1d",
            "placeholder": "",
            "style": "IPY_MODEL_32dfe218c9d5444fb316da118c00ed09",
            "value": "1/1[00:00&lt;00:00,7.02example/s]"
          }
        },
        "5341f040ca9a41188f37b48f116f61a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "68623bbfb0414aa7b7a01ecd4d165dbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3b0529a4a494a69a6f4de0dc21493bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0ad189aa4b34a28b1687a01b96804b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41fa16f362f24da088ca7697b6f1f035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "201425c31328429cb9e761614800ba1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32dfe218c9d5444fb316da118c00ed09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}